{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tabel\"></a>\n",
    "<b>Table of contents:</b>\n",
    "\n",
    "* [1. About Dataset](#about)\n",
    "* [2. Import Libraries & Dataset](#import)\n",
    "* [3. Overview of Dataset](#overview)\n",
    "* [4. Cleaning Dataset](#clean)\n",
    "* [5. Exploratory Data Analysis (EDA)](#eda)\n",
    "    - [5.1. Univariate Analysis](#univariate)\n",
    "    - [5.2. Bivariate Analysis](#bivariate)\n",
    "    - [5.3. Multivariate Analysis](#multivariate)\n",
    "* [6. Models and Improve Models](#model)\n",
    "    - [6.1. MultinomialNB( )](#multinomial)\n",
    "    - [6.2. CategoricalNB( )](#categorical)\n",
    "    - [6.3. ComplementNB( )](#complement)\n",
    "    - [6.4. BernoulliNB( )](#bernoulli)\n",
    "    - [6.5. LogisitcRegression( )](#logistic)\n",
    "    - [6.6. KNN: KNeighborsClassifier( )](#knn)\n",
    "    - [6.7. Decision tree](#dt)\n",
    "    - [6.8. Random Forest](#rf)\n",
    "* [7. Comparing Models](#compare)\n",
    "* [8. Visualization Final Model](#visualize)\n",
    "* [9. Prediction Sample Data](#predict)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><center style=\"font-family:cursive; color:orange;font-size:120%;\">In the name of God</center></p>\n",
    "\n",
    "# <p><center style=\"font-family:newtimeroman;font-size:180%;\">üí∏Bank Personal Loan Modelingüí∏</center></p>\n",
    "\n",
    "<p><center style=\"color:#159364; font-family:cursive;font-size:100%;\">Thanks for visiting my notebook </center></p>\n",
    "\n",
    "***\n",
    "<br>\n",
    "<center><img src='https://miro.medium.com/max/1012/1*tF1iKXHs9qypE_E2fQqytQ.png' height=300px width=750px></center><br>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana;\">\n",
    "    üìå Feel free to fork or edit the notebook for your own convenience. If you liked the notebook, consider upvoting. It helps other people discover the notebook as well. Your support inspires me to produce more of these kernel.üòä\n",
    "</div>\n",
    "\n",
    "## <p style=\"font-family:newtimeroman;font-size:80%;\">ü§î Data Set Problems</p>\n",
    "This case is about a bank (Thera Bank) whose management wants to explore ways of converting its liability customers to personal loan customers (while retaining them as depositors). A campaign that the bank ran last year for liability customers showed a healthy conversion rate of over 9% success. This has encouraged the retail marketing department to devise campaigns with better target marketing to increase the success ratio with minimal budget.\n",
    "<br><br>\n",
    "\n",
    "## <p style=\"font-family:newtimeroman;font-size:80%;\">üéØ Objectives of Notbook</p>\n",
    "**This notebook aims to:**\n",
    "*   Cleaning Dataset\n",
    "*   Dataset exploration using various types of data visualization.\n",
    "*   Identifying suitable patterns for modeling (Pattern Recognition)\n",
    "*   Build various ML models that can predict personal loan customers.\n",
    "<br><br>\n",
    "\n",
    "üë®‚Äçüíª **The machine learning models used in this project are:** \n",
    "1. Multinomial Naive Bayes\n",
    "2. Categorical Naive Bayes\n",
    "3. Bernoulli Naive Bayes\n",
    "4. Complement Naive Bayes\n",
    "5. Logistic Regression\n",
    "6. KNN\n",
    "7. Decision Tree\n",
    "8. Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about\"></a>\n",
    "# <p style=\"background-color:#145A32;font-family:newtimeroman;font-size:120%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">1. About Dataset</p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)\n",
    "\n",
    "The file bank_personal_loan.csv contains data on 5000 customers. The data include customer demographic information (age, income, etc.), the customer's relationship with the bank (mortgage, securities account, etc.), and the customer response to the last personal loan campaign (Personal Loan). Among these 5000 customers, only 480 (= 9.6%) accepted the personal loan that was offered to them in the earlier campaign.\n",
    "\n",
    "There are no empty or (NaN) values in the dataset. The dataset has a mix of numerical and categorical attributes, but all categorical data are represented with numbers. Moreover, Some of the predictor variables are heavily skewed (long - tailed), making the data pre-processing an interesting yet not too challenging aspect of the data.\n",
    "\n",
    "The following is the **structure of the data set**:\n",
    "\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th style=\"text-align:center; font-weight: bold; font-size:20px\">Variable Name</th>\n",
    "<th style=\"text-align:center; font-weight: bold; font-size:20px\">Description</th>\n",
    "<th style=\"text-align:center; font-weight: bold; font-size:20px\">Sample Data</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><b>ID</b></td>\n",
    "<td>Customer ID</td>\n",
    "<td>1, 2, ...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Age</b></td>\n",
    "<td>Customer's age in completed years</td>\n",
    "<td>25, 45, ...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Experience</b></td>\n",
    "<td><br>Years of professional experience</td>\n",
    "<td>1, 19, ...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Income</b></td>\n",
    "<td>Annual income of the customer (1000 Dollar)</td>\n",
    "<td>49, 34, ...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Zip Code</b></td>\n",
    "<td>Home Address ZIP code</td>\n",
    "<td>91107, 90089, ...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Family</b></td>\n",
    "<td>Family size of the customer<br> (1, 2, 3, 4)</td>\n",
    "<td>4, 3, ...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>CCAvg</b></td>\n",
    "<td>Avg. spending on credit cards per month (1000 Dollar)</td>\n",
    "<td>1/60, 1/50, ...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Education</b></td>\n",
    "<td>Education Level<br>(1: Undergrad; 2: Graduate; 3: Advanced/Professional)</td>\n",
    "<td>1, 2, ...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Mortgage</b></td>\n",
    "<td>Value of house mortgage if any. ($1000)</td>\n",
    "<td>0, 101, ...</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Personal Loan</b></td>\n",
    "<td>Did this customer accept the personal loan offered in the last campaign?<br>(0, 1)</td>\n",
    "<td>0, 1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Securityaccount</b></td>\n",
    "<td>Does the customer have a securities account with this bank?<br>(0, 1)</td>\n",
    "<td>0, 1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Cd_account</b></td>\n",
    "<td>Does the customer have a certificate of deposit (CD) account with this bank?<br>(0, 1)</td>\n",
    "<td>0, 1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Online</b></td>\n",
    "<td>Does the customer use internet banking facilities?<br>(0, 1)</td>\n",
    "<td>0, 1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>CreditCard</b></td>\n",
    "<td>Does the customer use a credit card issued by Universal Bank?<br>(0, 1)</td>\n",
    "<td>0, 1</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"import\"></a>\n",
    "# <p style=\"background-color:#145A32;font-family:newtimeroman;font-size:120%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">2. Import Libraries & Dataset</p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:47.145641Z",
     "iopub.status.busy": "2022-11-13T19:41:47.144385Z",
     "iopub.status.idle": "2022-11-13T19:41:49.185116Z",
     "shell.execute_reply": "2022-11-13T19:41:49.183926Z",
     "shell.execute_reply.started": "2022-11-13T19:41:47.14552Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import requirement libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# for solve problem of show plotly plots\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# Optional\n",
    "# for filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# for better plot visualization \n",
    "plt.style.use('_mpl-gallery')\n",
    "FONT = {'fontsize':20, 'fontstyle':'normal', 'fontfamily':'Times New Roman', 'backgroundcolor':'#145A32', 'color':'orange'} # for plot title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:49.188492Z",
     "iopub.status.busy": "2022-11-13T19:41:49.187378Z",
     "iopub.status.idle": "2022-11-13T19:41:49.582338Z",
     "shell.execute_reply": "2022-11-13T19:41:49.581254Z",
     "shell.execute_reply.started": "2022-11-13T19:41:49.188442Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import requirement sklearn functions\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, jaccard_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:49.584157Z",
     "iopub.status.busy": "2022-11-13T19:41:49.583763Z",
     "iopub.status.idle": "2022-11-13T19:41:49.64772Z",
     "shell.execute_reply": "2022-11-13T19:41:49.646509Z",
     "shell.execute_reply.started": "2022-11-13T19:41:49.584125Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import bank_personal_loan dataset\n",
    "data = pd.read_csv('../input/bank-personal-loan/bank_loan.csv')\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "# <p style=\"background-color:#145A32;font-family:newtimeroman;font-size:120%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">3. Overview of Dataset</p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:49.651064Z",
     "iopub.status.busy": "2022-11-13T19:41:49.650685Z",
     "iopub.status.idle": "2022-11-13T19:41:49.666828Z",
     "shell.execute_reply": "2022-11-13T19:41:49.665568Z",
     "shell.execute_reply.started": "2022-11-13T19:41:49.651033Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:49.669576Z",
     "iopub.status.busy": "2022-11-13T19:41:49.668714Z",
     "iopub.status.idle": "2022-11-13T19:41:49.705452Z",
     "shell.execute_reply": "2022-11-13T19:41:49.704256Z",
     "shell.execute_reply.started": "2022-11-13T19:41:49.669526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ According to above information:\n",
    " - Dataset has 5000 datapoints.\n",
    " - Dataset has 14 columns including:\n",
    "   - 13 columns by int64 type: `ID`, `Age`, `Experience`, `Income`, `ZIP Code`, `Family`, `Education`, `Moragage`, `Personal Loan`, `Securities Account`, `CD Account`, `Online` and `CreditCard`\n",
    "   - 1 column by object type: `CCAvg`\n",
    " - Target is `Personal Loan` column and other columns are features.\n",
    " - It seems that there is no missing value, but there may be invalid values, so we will check this case further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"clean\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:120%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">4. Cleaning Dataset</p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the / sign in column CCAvg represents a decimal. Therefore, we first correct the CCAvg column by replace . instead of / and then convert type of CCAvg to float64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:49.708566Z",
     "iopub.status.busy": "2022-11-13T19:41:49.707193Z",
     "iopub.status.idle": "2022-11-13T19:41:49.734304Z",
     "shell.execute_reply": "2022-11-13T19:41:49.732879Z",
     "shell.execute_reply.started": "2022-11-13T19:41:49.708517Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['CCAvg'] = df['CCAvg'].str.replace('/', '.').astype('float64')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:49.736637Z",
     "iopub.status.busy": "2022-11-13T19:41:49.736001Z",
     "iopub.status.idle": "2022-11-13T19:41:49.747659Z",
     "shell.execute_reply": "2022-11-13T19:41:49.746682Z",
     "shell.execute_reply.started": "2022-11-13T19:41:49.736597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:49.749541Z",
     "iopub.status.busy": "2022-11-13T19:41:49.749171Z",
     "iopub.status.idle": "2022-11-13T19:41:49.818934Z",
     "shell.execute_reply": "2022-11-13T19:41:49.817676Z",
     "shell.execute_reply.started": "2022-11-13T19:41:49.749489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20) # for show all rows\n",
    "round(df.describe().T, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we have a negative value in the Experience column, which is illogical, so since we do not have access to the owner of the data, we assume that the negative data was actually positive, so we convert the negative numbers into positive ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:49.821427Z",
     "iopub.status.busy": "2022-11-13T19:41:49.820678Z",
     "iopub.status.idle": "2022-11-13T19:41:49.850755Z",
     "shell.execute_reply": "2022-11-13T19:41:49.849333Z",
     "shell.execute_reply.started": "2022-11-13T19:41:49.821384Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# find negative values in Experience columns\n",
    "df[df['Experience'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:49.857193Z",
     "iopub.status.busy": "2022-11-13T19:41:49.856646Z",
     "iopub.status.idle": "2022-11-13T19:41:49.895281Z",
     "shell.execute_reply": "2022-11-13T19:41:49.894027Z",
     "shell.execute_reply.started": "2022-11-13T19:41:49.857147Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# convert above 52 rows to positive value\n",
    "df[df['Experience'] < 0] = df[df['Experience'] < 0].abs()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:49.898662Z",
     "iopub.status.busy": "2022-11-13T19:41:49.89719Z",
     "iopub.status.idle": "2022-11-13T19:41:49.919076Z",
     "shell.execute_reply": "2022-11-13T19:41:49.917807Z",
     "shell.execute_reply.started": "2022-11-13T19:41:49.898602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check missing values\n",
    "df.isna().sum().to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Nice. No missing values. Let's continuous to check invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:49.921484Z",
     "iopub.status.busy": "2022-11-13T19:41:49.920606Z",
     "iopub.status.idle": "2022-11-13T19:41:49.937395Z",
     "shell.execute_reply": "2022-11-13T19:41:49.936048Z",
     "shell.execute_reply.started": "2022-11-13T19:41:49.921436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check invalid valuse\n",
    "for col in df:\n",
    "    print(f\"{col} has {df[col].nunique()} unique value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:49.940424Z",
     "iopub.status.busy": "2022-11-13T19:41:49.939624Z",
     "iopub.status.idle": "2022-11-13T19:41:49.959921Z",
     "shell.execute_reply": "2022-11-13T19:41:49.958574Z",
     "shell.execute_reply.started": "2022-11-13T19:41:49.940377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check value counts of column that appear categorical accoring to above results\n",
    "discrete_cols1 = ['Family', 'Education', 'Personal Loan', 'Securities Account', 'CD Account', 'Online', 'CreditCard']\n",
    "for col in discrete_cols1:\n",
    "    print(f\"{col}:\\n{df[col].value_counts()}\")\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ OK. According to above results and type of columnsŸà We conclude that there are no invalid values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:49.962549Z",
     "iopub.status.busy": "2022-11-13T19:41:49.961848Z",
     "iopub.status.idle": "2022-11-13T19:41:49.976127Z",
     "shell.execute_reply": "2022-11-13T19:41:49.974757Z",
     "shell.execute_reply.started": "2022-11-13T19:41:49.962505Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# now check duplicated data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Well, there is no duplicate data\n",
    "\n",
    "Now we remove columns that not require for create model i.e. `ID`, `ZIP Code`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:49.978945Z",
     "iopub.status.busy": "2022-11-13T19:41:49.977894Z",
     "iopub.status.idle": "2022-11-13T19:41:50.005644Z",
     "shell.execute_reply": "2022-11-13T19:41:50.004162Z",
     "shell.execute_reply.started": "2022-11-13T19:41:49.978896Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# drop ID and ZIP Code columns\n",
    "df.drop(['ID', 'ZIP Code'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now check outliers and noisy data. For this step we use scatter plot and box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:50.00805Z",
     "iopub.status.busy": "2022-11-13T19:41:50.007461Z",
     "iopub.status.idle": "2022-11-13T19:41:55.039025Z",
     "shell.execute_reply": "2022-11-13T19:41:55.037828Z",
     "shell.execute_reply.started": "2022-11-13T19:41:50.007914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check noisy data\n",
    "%matplotlib inline\n",
    "sns.set_palette('summer')\n",
    "dnp = sns.pairplot(df.loc[:, ~df.columns.isin(discrete_cols1)])\n",
    "dnp.fig.suptitle('Detect Noisy Data', y=1.02, **FONT)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana;\">\n",
    "    üìå In the box plot below, you can select the columns you want, from the right side of the chart to display.üòä\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:55.041256Z",
     "iopub.status.busy": "2022-11-13T19:41:55.040621Z",
     "iopub.status.idle": "2022-11-13T19:41:55.169338Z",
     "shell.execute_reply": "2022-11-13T19:41:55.168376Z",
     "shell.execute_reply.started": "2022-11-13T19:41:55.041218Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for col in df:\n",
    "    fig.add_trace(go.Box(x=df[col], name=col))\n",
    "fig.update_layout(\n",
    "    title_text=\"Box Plot Styling Outliers\",\n",
    "    title_font=dict(color='orange', family='newtimeroman', size=25),\n",
    "    title_x=0.45,\n",
    "    paper_bgcolor='#145A32',\n",
    "    # plot_bgcolor='#DAF7A6',\n",
    "    font=dict(color='#DAF7A6', family='newtimeroman', size=16),\n",
    "    )\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An outlier is an observation that is unlike the other observations and we see some of these in above boxplot for some comlumns but <font color='red'>outliers are innocent until proven guilty</font>. With that being said, they should not be removed unless there is a good reason for that. According to pairplot, noisy data does not appear to exist. Therefore, we do not delete any data.\n",
    "\n",
    "Now everything is ok. There is only one small point that needs to be fixed. As it was said in section 1, the Income column expresses the annual income, while the CCAvg column expresses the Avg. spending on credit cards per month, so to standardize the units of the columns, we convert the annual income to monthly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:55.171141Z",
     "iopub.status.busy": "2022-11-13T19:41:55.17063Z",
     "iopub.status.idle": "2022-11-13T19:41:55.19306Z",
     "shell.execute_reply": "2022-11-13T19:41:55.191398Z",
     "shell.execute_reply.started": "2022-11-13T19:41:55.17111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# convert annual income to monthly with divide by 12\n",
    "df['Income'] = round(df['Income']/12, 2)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eda\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:120%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">5. Exploratory Data Analysis (EDA)</p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)\n",
    "\n",
    "Before univariate analysis we check distribution of each columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:55.195242Z",
     "iopub.status.busy": "2022-11-13T19:41:55.194872Z",
     "iopub.status.idle": "2022-11-13T19:41:57.781665Z",
     "shell.execute_reply": "2022-11-13T19:41:57.780676Z",
     "shell.execute_reply.started": "2022-11-13T19:41:55.19521Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check distribution Scatter matrix (splom) with go.Splom\n",
    "sns.set_palette('summer')\n",
    "fig, ax = plt.subplots(4,3,figsize=(12,20))\n",
    "for i, col in enumerate(df):\n",
    "    sns.histplot(df[col], kde=True, ax=ax[i//3, i%3])\n",
    "fig.suptitle('Distribution of Columns', y=1.02, **FONT)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"univariate\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:100%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">5.1. Univariate Analysis</p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:57.784545Z",
     "iopub.status.busy": "2022-11-13T19:41:57.783675Z",
     "iopub.status.idle": "2022-11-13T19:41:59.416178Z",
     "shell.execute_reply": "2022-11-13T19:41:59.414965Z",
     "shell.execute_reply.started": "2022-11-13T19:41:57.784496Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# univariate analysis of categorical data:\n",
    "sns.set_palette(\"summer_r\")\n",
    "for i, col in enumerate(discrete_cols1):\n",
    "\n",
    "    fig, axes = plt.subplots(1,2,figsize=(10,4))\n",
    "\n",
    "    # count of col (countplot)\n",
    "    sns.countplot(data=df, x=col, ax=axes[0])\n",
    "    for container in axes[0].containers:\n",
    "        axes[0].bar_label(container)\n",
    "    # count of col (pie chart)\n",
    "    slices = df[col].value_counts().sort_index().values\n",
    "    activities = [var for var in df[col].value_counts().sort_index().index]\n",
    "    axes[1].pie(slices, labels=activities, shadow=True, autopct='%1.1f%%')\n",
    "\n",
    "    plt.suptitle(f'Count of Unique Value in {col} (Fig {i+1})', y=1.09, **FONT)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:59.417705Z",
     "iopub.status.busy": "2022-11-13T19:41:59.417369Z",
     "iopub.status.idle": "2022-11-13T19:41:59.452936Z",
     "shell.execute_reply": "2022-11-13T19:41:59.451717Z",
     "shell.execute_reply.started": "2022-11-13T19:41:59.417676Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# univariate analysis of numerical data:\n",
    "df.loc[:, ~df.columns.isin(discrete_cols1)].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ According to above plots and tabel:\n",
    " - Customers with the number of Family 1 and the number of Family 3 respectively have the highest frequency and the lowest frequency, but in general, the customers with the number of Family 1, 2, 3, and 4 are almost equally distributed in the dataset (Fig 1).\n",
    " - The customers who did not accept a Personal Loan are much more than the customers who accepted a Personal Loan, and therefore there is an imbalance in the classes, so we must be careful to consider the imbalance in the model section for resampling the data.\n",
    " - Most of the bank's customers have education level 1 i.e. Undergrad (Fig 2).\n",
    " - Most of the bank's customers (90.4%) did not accept the personal loan offer (Fig 3).\n",
    " - Most of the bank's customers (89.6%) did not have a Securities Account (Fig 4).\n",
    " - Most of the bank's customers (94%) did not have a CD Account (Fig 5).\n",
    " - Most of the bank's customers (59.7%) used internet banking facilities (Fig 6).\n",
    " - Most of the bank's customers (70.6%) did not use a credit card issued by Universal Bank(Fig 6).\n",
    " - The Age range of customers is between 23 and 67 years. The average age of customers is almost 45.\n",
    " - The Experience range of customers is between 0 and 43 years. The mean age of customers is almost 20.\n",
    " - The age and experience columns have a similar distribution. Also, the column of income, mortgage and average distribution are almost similar, all of them are skewed to the right.\n",
    " - The average income of the bank's customers per month is approximately 6 thousand dollars and its range is between 0.67 and 18.67 thousand dollars. CCAvg of the bank's customers per month is approximately 1.94 thousand dollars and its range is between 0 and 10 thousand dollars.\n",
    " - The average Mortgage of the bank's customers is approximately 56 thousand dollars and its range is between 0 and 635 thousand dollars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bivariate\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:100%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">5.2. Bivariate Analysis</p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:41:59.454909Z",
     "iopub.status.busy": "2022-11-13T19:41:59.454524Z",
     "iopub.status.idle": "2022-11-13T19:42:00.622529Z",
     "shell.execute_reply": "2022-11-13T19:42:00.620976Z",
     "shell.execute_reply.started": "2022-11-13T19:41:59.454876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check distribution of Income (based on Personal Loan)\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-notebook')\n",
    "sns.set_palette(['green','orange'])\n",
    "for j, col in enumerate(['Income','Mortgage','CCAvg','Age']):\n",
    "    for i, label in enumerate(df['Personal Loan'].unique().tolist()):\n",
    "        sns.kdeplot(df.loc[df['Personal Loan'] == label, col], label=label, shade=True)\n",
    "    plt.title(f'1. KDE of {col} based on Personal Loan (Fig {j+1})', fontdict=FONT, pad=15)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ According to above plots:\n",
    " - The Income of people who have accepted a bank loan is often higher than that of people who have not accepted a bank loan. Approximately, people whose monthly Income is more than 8 thousand dollars have accepted a bank loan (Fig 1)\n",
    " - Most people who accepted a bank loan had mortgage euqal to zero (Fig 2).\n",
    " - The CCAvg of people who have accepted a bank loan is often higher than that of people who have not accepted a bank loan. Approximately, people whose CCAvg is more than 3 thousand dollars have accepted a bank loan (Fig 3).\n",
    " - It seems that age does not have much influence in determining whether or not to accept a bank loan (Fig 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:00.624438Z",
     "iopub.status.busy": "2022-11-13T19:42:00.623976Z",
     "iopub.status.idle": "2022-11-13T19:42:02.296278Z",
     "shell.execute_reply": "2022-11-13T19:42:02.295495Z",
     "shell.execute_reply.started": "2022-11-13T19:42:00.624404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# count of purchased based on Gender\n",
    "%matplotlib inline\n",
    "sns.set_palette(['#1f4a1b','orange','#bbff33','yellow'])\n",
    "discrete_cols2 = ['Family', 'Education', 'Securities Account', 'CD Account', 'Online', 'CreditCard']\n",
    "for i, col in enumerate(discrete_cols2):\n",
    "    ax = sns.countplot(data=df, x='Personal Loan', hue=col)\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container)\n",
    "    plt.title(f'Count of Personal Loan based on {col} (Fig {i+5})', fontdict=FONT, pad=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ According to above plots:\n",
    " - Among the people who did not accept the personal loan, most of them had a family equal to 1, but among the people who accepted the personal loan, there is not much difference in terms of family (Fig 5).\n",
    " - Among the people who did not accept the personal loan, most of them had an Education of 1, but among the people who accepted the personal loan, the Education was mostly 3 or 2 (Fig 6).\n",
    " - Most of the people, both those who accepted the personal loan and those who did not, did not have a Securities Account (Fig 7).\n",
    " - Most of the people, both those who accepted the personal loan and those who did not, did not have a CD Account (Fig 8).\n",
    " - Most of the people, both those who accepted the personal loan and those who did not, used online banking facilities (Fig 9).\n",
    " - Most of the people, both those who accepted the personal loan and those who did not, did not use a Creditcard (Fig 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:02.298233Z",
     "iopub.status.busy": "2022-11-13T19:42:02.297369Z",
     "iopub.status.idle": "2022-11-13T19:42:08.399854Z",
     "shell.execute_reply": "2022-11-13T19:42:08.398647Z",
     "shell.execute_reply.started": "2022-11-13T19:42:02.298199Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Mean of Income and CCAvg based on each feature\n",
    "for i, col in enumerate(['Income', 'CCAvg','Mortgage']):\n",
    "    print('='*30, f\"Mean of {col} in each categorical feature\", '='*30)\n",
    "    for j, cat in enumerate(discrete_cols2):\n",
    "        fig , ax= plt.subplots(1,2, figsize=(10,4))\n",
    "        gp = df.groupby([cat])[col].mean().to_frame().reset_index()\n",
    "        sns.barplot(data=gp, x=cat, y=col, ax=ax[0])\n",
    "        for container in ax[0].containers:\n",
    "            ax[0].bar_label(container)\n",
    "        ax[0].set_title(f'Mean of {col} (based on {cat})', y=1.09, **FONT)\n",
    "\n",
    "        sns.boxplot(data=df, x=cat, y=col, ax=ax[1])\n",
    "        ax[1].set_title(f'Boxplot of {cat} (Fig {i+11}-{j+1})', y=1.09, **FONT)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:08.40201Z",
     "iopub.status.busy": "2022-11-13T19:42:08.401517Z",
     "iopub.status.idle": "2022-11-13T19:42:09.275476Z",
     "shell.execute_reply": "2022-11-13T19:42:09.274212Z",
     "shell.execute_reply.started": "2022-11-13T19:42:08.40195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# draw heatplot of correlation between columns\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(round(df.corr(),2), cmap='Greens', annot=True)\n",
    "plt.title('Heatmap of Correlations', y=1.02, fontdict=FONT)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ According to above plots:\n",
    " - Customers whose Family was 2 had the highest average Income (7.02 thousand $, Fig 11-1).\n",
    " - Unexpectedly, customers whose Education was 1 had the highest average Income (7.13 thousand $, Fig 11-2).\n",
    " - The average income of customers whose Secutities Account and CreditCard and Online was 1 is the same as that of those was zero(6.1 thousand $, Fig 11-3,5,6).\n",
    " - The average income of those who have a CD account is higher than that of customers who do not have a CD account (8.7 thousand $, Fig 11-4).\n",
    " - Similar results can be obtained for the CCAvg and Mortgage average, which shows that the behavior of the CCAvg, Mortgage and Income columns is somewhat similar to each other (Fig 12-1 to 13-6).\n",
    " - According to the heatmap, Personal Loan has the highest correlation with Income, CCAvg and CD Account respectively.\n",
    " - Age and experience have a completely linear relationship with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"multivariate\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:100%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">5.3. Multivariate Analysis</p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:09.278055Z",
     "iopub.status.busy": "2022-11-13T19:42:09.277212Z",
     "iopub.status.idle": "2022-11-13T19:42:21.414049Z",
     "shell.execute_reply": "2022-11-13T19:42:21.413185Z",
     "shell.execute_reply.started": "2022-11-13T19:42:09.278019Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# draw pairplot with hue = Personal Loan\n",
    "sns.set_palette(['#1f4a1b','orange','#bbff33','yellow'])\n",
    "splot = sns.pairplot(data=df, x_vars=['Age','Experience','Income','CCAvg','Mortgage'], y_vars=['Age','Experience','Income','CCAvg','Mortgage'], hue='Personal Loan')\n",
    "splot.fig.suptitle('Scatter plot of continuous feature (hue = Personal Loan)', y=1.05, **FONT)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:21.416269Z",
     "iopub.status.busy": "2022-11-13T19:42:21.415311Z",
     "iopub.status.idle": "2022-11-13T19:42:22.858757Z",
     "shell.execute_reply": "2022-11-13T19:42:22.857849Z",
     "shell.execute_reply.started": "2022-11-13T19:42:21.416233Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "continuous_cols = ['Age','Experience','CCAvg','Mortgage']\n",
    "\n",
    "for i, col in enumerate(continuous_cols):\n",
    "    fig = px.scatter_3d(\n",
    "        data_frame= df,\n",
    "        x=df.Income,\n",
    "        y=df[col],\n",
    "        z=df['Personal Loan'],\n",
    "        color=df['Personal Loan'].astype(str),\n",
    "        color_discrete_map={'1':'orange', '0':'red'},\n",
    "        template='ggplot2',\n",
    "        hover_name='Age',\n",
    "        # hover_data=\n",
    "        opacity=0.6,\n",
    "        # symbol='Transmission',\n",
    "        # symbol_map=\n",
    "        # log_x=True,\n",
    "        # log_z=True,\n",
    "        height=700,\n",
    "        title=f'3D scatter of features based on Personal Loan (Fig {i+1})')\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=\"Box Plot Styling Outliers\",\n",
    "        title_font=dict(color='orange', family='newtimeroman', size=25),\n",
    "        title_x=0.45,\n",
    "        paper_bgcolor='#145A32',\n",
    "        # plot_bgcolor='#DAF7A6',\n",
    "        font=dict(color='#DAF7A6', family='newtimeroman', size=16),\n",
    "    )\n",
    "    pio.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:22.867721Z",
     "iopub.status.busy": "2022-11-13T19:42:22.866886Z",
     "iopub.status.idle": "2022-11-13T19:42:23.136695Z",
     "shell.execute_reply": "2022-11-13T19:42:23.135858Z",
     "shell.execute_reply.started": "2022-11-13T19:42:22.867675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results = pd.pivot_table(data=df, index='CD Account', columns='Education', values='Personal Loan')\n",
    "sns.heatmap(results, cmap='Greens', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ According to above plots:\n",
    " - Customers whose Income is less than `$5 thousand ` per month have not accepted a personal loan.\n",
    " - Most customers whose income is less than `$10 thousand ` per month and their CCAvg is less than `$3 thousand ` per month have not accepted a personal loan.\n",
    " - 62% of customers whose CD Account was 1 and Education was 2 have accepted a personal loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:23.138716Z",
     "iopub.status.busy": "2022-11-13T19:42:23.138033Z",
     "iopub.status.idle": "2022-11-13T19:42:26.799024Z",
     "shell.execute_reply": "2022-11-13T19:42:26.797717Z",
     "shell.execute_reply.started": "2022-11-13T19:42:23.138681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6,2,figsize=(14,24))\n",
    "sns.stripplot(data=df, x='Education', y='Income', hue='Personal Loan', ax=ax[0,0])\n",
    "sns.stripplot(data=df, x='Education', y='CCAvg', hue='Personal Loan', ax=ax[0,1])\n",
    "sns.stripplot(data=df, x='Family', y='Income', hue='Personal Loan', ax=ax[1,0])\n",
    "sns.stripplot(data=df, x='Family', y='CCAvg', hue='Personal Loan', ax=ax[1,1])\n",
    "sns.stripplot(data=df, x='CD Account', y='Income', hue='Personal Loan', ax=ax[2,0])\n",
    "sns.stripplot(data=df, x='CD Account', y='CCAvg', hue='Personal Loan', ax=ax[2,1])\n",
    "sns.stripplot(data=df, x='Online', y='Income', hue='Personal Loan', ax=ax[3,0])\n",
    "sns.stripplot(data=df, x='Online', y='CCAvg', hue='Personal Loan', ax=ax[3,1])\n",
    "sns.stripplot(data=df, x='CreditCard', y='Income', hue='Personal Loan', ax=ax[4,0])\n",
    "sns.stripplot(data=df, x='CreditCard', y='CCAvg', hue='Personal Loan', ax=ax[4,1])\n",
    "sns.stripplot(data=df, x='Securities Account', y='Income', hue='Personal Loan', ax=ax[5,0])\n",
    "sns.stripplot(data=df, x='Securities Account', y='CCAvg', hue='Personal Loan', ax=ax[5,1])\n",
    "ax[0,0].set_title('Stripplot of Personal Loan vs Income',y=1.05, **FONT)\n",
    "ax[0,1].set_title('Stripplot of Personal Loan vs CCAvg',y=1.05, **FONT)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ According to above plots:\n",
    " - All customers with  of more than`$10 thousand` and with Education level 2 or 3, accepted Personal Loans.\n",
    " - All customers with CCAvg of more than `$5 thousand` and with Education level 2 or 3, accepted Personal Loans.\n",
    " - All customers with Income of more than `$10 thousand` and Family 3 or 4, accepted Personal Loans.\n",
    " - All customers with CCAvg of more than `$5 thousand` and by Family 3 or 4, accepted Personal Loans.\n",
    " - Most customers with Income of more than `$10 thousand` and by CD Account 1, accepted Personal Loans.\n",
    " - Most customers with CCAvg of more than `$5 thousand` and by CD Account 1, accepted Personal Loans.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:120%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">6. Models and Improve Models</p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact that the desired target has a label and the problem is of classification type, we use KNN, LogisticRegression, Naive Bayes, DTs and RF algorithms.\n",
    "\n",
    "Now, see our dataset again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:26.80172Z",
     "iopub.status.busy": "2022-11-13T19:42:26.800922Z",
     "iopub.status.idle": "2022-11-13T19:42:26.828833Z",
     "shell.execute_reply": "2022-11-13T19:42:26.827555Z",
     "shell.execute_reply.started": "2022-11-13T19:42:26.801674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the dataset used to build the model. For this, we first determine the values of X and Y and then check the different models in order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:26.831826Z",
     "iopub.status.busy": "2022-11-13T19:42:26.831172Z",
     "iopub.status.idle": "2022-11-13T19:42:26.83959Z",
     "shell.execute_reply": "2022-11-13T19:42:26.838276Z",
     "shell.execute_reply.started": "2022-11-13T19:42:26.831753Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# define x and y\n",
    "x = df.drop('Personal Loan', axis=1)\n",
    "y = df['Personal Loan'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:26.841781Z",
     "iopub.status.busy": "2022-11-13T19:42:26.841172Z",
     "iopub.status.idle": "2022-11-13T19:42:26.891038Z",
     "shell.execute_reply": "2022-11-13T19:42:26.889859Z",
     "shell.execute_reply.started": "2022-11-13T19:42:26.841734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Model = []\n",
    "FPR = []\n",
    "TPR = []\n",
    "ACC_test = []\n",
    "ACC_train = []\n",
    "Recall = []\n",
    "Precision = []\n",
    "F1 = []\n",
    "AUC = []\n",
    "\n",
    "def delete_results():\n",
    "    \"\"\"Delete results of Previous models for preveing to avoid congestion in ROC charts\"\"\"\n",
    "    global FPR, TPR, ACC_test, ACC_train, Recall, Precision, F1, AUC\n",
    "    del FPR[:]\n",
    "    del TPR[:]\n",
    "    del ACC_test[:]\n",
    "    del ACC_train[:]\n",
    "    del Recall[:]\n",
    "    del Precision[:]\n",
    "    del F1[:]\n",
    "    del AUC[:]\n",
    "\n",
    "def plot_confusion_matrix2(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function plots the confusion matrix.\n",
    "        cm(array): confusion matrix\n",
    "        classes(dictionary): classes of our target (key=categorical type, value=numerical type)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.grid(False)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "\n",
    "    plt.xticks(tick_marks, [f\"{value}={key}\" for key , value in classes.items()], rotation=45)\n",
    "    plt.yticks(tick_marks, [f\"{value}={key}\" for key , value in classes.items()])\n",
    "    names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for k, (i,j) in enumerate(itertools.product(range(cm.shape[0]), range(cm.shape[1]))):\n",
    "        plt.text(j, i, f\"{names[k]}\\n{cm[i,j]}\\n{cm[i,j]/np.sum(cm)*100:.2f}%\",\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    \n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "def Perform_cross_val(model, k, x, y, scoring):\n",
    "    \"\"\"\n",
    "    perform cross validation\n",
    "        model: model\n",
    "        k(scaler): the value for n_splits in KFold()\n",
    "        x(DataFrame or array):  x_train\n",
    "        y(DataFrame or array): y_train\n",
    "        scoring(string): an approach for evaluation in cross validation\n",
    "    \"\"\"\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=k)\n",
    "    cv_results = cross_val_score(model, x, y.ravel(), cv=kf, scoring=scoring)\n",
    "    cv_mean = np.mean(cv_results)\n",
    "    \n",
    "    print('-'*20, f\"CV for k={k}, scoring={scoring}\", '-'*20)\n",
    "    print(f\"CV mean: {cv_mean}\")\n",
    "    print(f\"CV results: {cv_results}\\n\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "def find_fold_index(k, x):\n",
    "    \"\"\"\n",
    "    Find fold index in kfold\n",
    "        k(scaler): the value used for n_splits in KFold()\n",
    "        x(DataFrame or array): x_train\n",
    "    \"\"\"\n",
    "\n",
    "    my_fold_index = []\n",
    "    j=1\n",
    "    for _ , test in KFold(k).split(x):\n",
    "\n",
    "        my_fold_index = []\n",
    "        for i in test:\n",
    "            my_fold_index.append(i)\n",
    "        print(f\"fold {j}: [{my_fold_index[0]},{my_fold_index[-1]}]\")\n",
    "        print(20*'-')\n",
    "        j += 1\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "def change_test_size(model, x, y, name):\n",
    "    # try to imporve model by changing test_size\n",
    "    test_sizes= [0.2, 0.25, 0.3, 0.35, 0.4, 0.45]\n",
    "    acc_table = pd.DataFrame(columns=['Model', 'test_size', 'ACC_train', 'ACC_test', 'Recall_train', 'Recall_test'])\n",
    "    for i, test_size in enumerate(test_sizes):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=0, stratify=y)\n",
    "        model.fit(x_train, y_train.ravel())\n",
    "        y_pred_train = model.predict(x_train)\n",
    "        y_pred_test = model.predict(x_test)\n",
    "        acc_test_i = accuracy_score(y_test, y_pred_test)\n",
    "        acc_train_i = accuracy_score(y_train, y_pred_train)\n",
    "        rec_test_i = recall_score(y_test, y_pred_test)\n",
    "        rec_train_i = recall_score(y_train, y_pred_train)\n",
    "        acc_table.loc[len(acc_table.index)] = [f\"{name} {i+1}\", str(test_size), acc_train_i, acc_test_i, rec_train_i, rec_test_i]\n",
    "    return acc_table.sort_values(by=['Recall_test'], ascending=False).style.background_gradient(cmap='summer_r')\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "def plot_results(FPR, TPR, AUC, ACC_test, ACC_train, Recall, Precision, F1, y_proba_test, y_test, model_name, Model):\n",
    "    \"\"\"\n",
    "    draw ROC curve and plot of Recall, precision, f1 score etc.\n",
    "        FPR(list): list of False Positive Rate\n",
    "        TPR(list): list of True Positive Rate\n",
    "        ACC(list): list of accuracy of models\n",
    "        Recall(list): list of recall score of models\n",
    "        Precision(list): list of Precision score of models\n",
    "        F1(list): list of F1 score of models \n",
    "        classes(dictionary): classes of our target (key=categorical type, value=numerical type)\n",
    "    \"\"\"\n",
    "    fig1 = go.Figure()\n",
    "    fig2 = go.Figure()\n",
    "    # the green line represents where TPR = FPR\n",
    "    fig1.add_shape(type='line', line=dict(color='green', dash='dash'),x0=0, x1=1, y0=0, y1=1)\n",
    "    for fpr_i, tpr_i, auc_i, name in zip(FPR, TPR, AUC, Model):\n",
    "        # ROC Curve\n",
    "        fig1.add_trace(go.Scatter(x=fpr_i, y=tpr_i, name=f\"{name} AUC = {auc_i:.4f}\", mode='lines'))\n",
    "    # the histogram of scores compared to true labels\n",
    "    fig_hist = px.histogram(x=y_proba_test[:,1], color=y_test.ravel(), nbins=50, labels=dict(color='Personal Loan', x='Probability'))\n",
    "    fig2.add_trace(fig_hist.data[0])\n",
    "    fig2.add_trace(fig_hist.data[1])\n",
    "    # Reduce opacity to see both histograms\n",
    "    fig2.update_traces(opacity=0.75)\n",
    "\n",
    "    # Accuracy plot\n",
    "    fig3 = make_subplots(rows=1, cols=2)\n",
    "    fig3.add_trace(go.Scatter(y=ACC_test, mode='lines+markers', name='ACC test', hovertemplate=\"<b>%{text}</b><br>\" +\"(%{x},%{y})\", text=Model), row=1, col=1)\n",
    "    fig3.add_trace(go.Scatter(y=Recall, mode='lines+markers', name='Recall', hovertemplate=\"<b>%{text}</b><br>\" +\"(%{x},%{y})\", text=Model), row=1, col=1)\n",
    "    fig3.add_trace(go.Scatter(y=Precision, mode='lines+markers', name='Precision', hovertemplate=\"<b>%{text}</b><br>\" +\"(%{x},%{y})\", text=Model), row=1, col=1)\n",
    "    fig3.add_trace(go.Scatter(y=F1, mode='lines+markers', name='F1 score', hovertemplate=\"<b>%{text}</b><br>\" +\"(%{x},%{y})\", text=Model), row=1, col=1)\n",
    "\n",
    "    fig3.add_trace(go.Scatter(y=ACC_train, mode='lines+markers', name='ACC train', hovertemplate=\"<b>%{text}</b><br>\" +\"(%{x},%{y})\", text=Model), row=1, col=2)\n",
    "    fig3.add_trace(go.Scatter(y=ACC_test, mode='lines+markers', name='ACC test', hovertemplate=\"<b>%{text}</b><br>\" +\"(%{x},%{y})\", text=Model), row=1, col=2)\n",
    "\n",
    "    # update layout and show figs\n",
    "    \n",
    "    fig1.update_layout(\n",
    "        title= 'ROC curve and AUC score',\n",
    "        xaxis_title='False Positive Rate',\n",
    "        yaxis_title='True Positive Rate',\n",
    "        yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "        xaxis=dict(constrain='domain'),\n",
    "        width=700, height=500,\n",
    "        showlegend=True)\n",
    "    fig2.update_layout(\n",
    "        # showlegend=True, \n",
    "        barmode='overlay',  # Overlay both histograms\n",
    "        title='Interpret ROC curve by histogram',\n",
    "        xaxis_title='Probability',\n",
    "        yaxis_title='Count')\n",
    "        \n",
    "    fig3.update_layout(\n",
    "        showlegend=True,\n",
    "        title='Model Evaluation & Train and Test Accuracy)',\n",
    "        xaxis_title='Model',\n",
    "        yaxis_title='Evaluation measure')\n",
    "    # Set custom x-axis labels\n",
    "    fig3.update_xaxes(ticktext=list(range(1,20)))\n",
    "    fig1.show()\n",
    "    fig2.show()\n",
    "    fig3.show()\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "def modeling(clf, x, y, test_size, classes, model_name, stratify=False):\n",
    "\n",
    "    # split data to train and test\n",
    "    if stratify:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=0, stratify=y)\n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=0)\n",
    "    print(20*'-', 'Shape', 20*'-')\n",
    "    print(f\"x_train: {x_train.shape}\")\n",
    "    print(f\"y_train: {y_train.shape}\")\n",
    "    print(f\"x_test: {x_test.shape}\")\n",
    "    print(f\"y_test: {y_test.shape}\")\n",
    "\n",
    "    classes1 = np.unique(y_test)\n",
    "    total = len(y_test)\n",
    "    print(15*'-', 'Class Distribution in y_test', 15*'-')\n",
    "    for c in classes1:\n",
    "        n_examples = len(y_test[y_test==c])\n",
    "        percent = n_examples / total * 100\n",
    "        print(f\"> Class={c:d} : {n_examples:d}/{total:d} ({percent:.1f}%)\")\n",
    "    \n",
    "    classes1 = np.unique(y_train)\n",
    "    total = len(y_train)\n",
    "    print(15*'-', 'Class Distribution in y_train', 15*'-')\n",
    "    for c in classes1:\n",
    "        n_examples = len(y_train[y_train==c])\n",
    "        percent = n_examples / total * 100\n",
    "        print(f\"> Class={c:d} : {n_examples:d}/{total:d} ({percent:.1f}%)\")\n",
    "    \n",
    "    # Normalization\n",
    "    # scaler = MinMaxScaler().fit(x_train)\n",
    "    x_norm_train = x_train\n",
    "    x_norm_test = x_test\n",
    "    # define model and fit model\n",
    "    clf.fit(x_train, y_train.ravel())\n",
    "\n",
    "    # prediction and results\n",
    "    y_pred_train = clf.predict(x_train)\n",
    "    y_pred_test = clf.predict(x_test)\n",
    "    y_proba_train = clf.predict_proba(x_train)\n",
    "    y_proba_test = clf.predict_proba(x_test)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba_test[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred_test)\n",
    "    acc_test = accuracy_score(y_test, y_pred_test)\n",
    "    acc_train = accuracy_score(y_train, y_pred_train)\n",
    "    rec_test = recall_score(y_test, y_pred_test)\n",
    "    rec_train = recall_score(y_train, y_pred_train)\n",
    "    pre = precision_score(y_test, y_pred_test)\n",
    "    f1 = f1_score(y_test, y_pred_test)\n",
    "\n",
    "    # append results\n",
    "    Model.append(model_name)\n",
    "    FPR.append(fpr)\n",
    "    TPR.append(tpr)\n",
    "    ACC_test.append(acc_test)\n",
    "    ACC_train.append(acc_train)\n",
    "    Recall.append(rec_test)\n",
    "    Precision.append(pre)\n",
    "    F1.append(f1)\n",
    "    AUC.append(roc_auc)\n",
    "\n",
    "    plot_results(FPR, TPR, AUC, ACC_test, ACC_train, Recall, Precision, F1, y_proba_test, y_test, model_name, Model)\n",
    "\n",
    "    # Evaluation model\n",
    "    print('-'*20 , 'Confusion Matrix', '-'*20)\n",
    "    print(cm)\n",
    "    plot_confusion_matrix2(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues)\n",
    "    # or use plot_confusion_matrix from sklearn.metrics\n",
    "    print('-'*20 , 'Classification Report', '-'*20)\n",
    "    print(classification_report(y_test, y_pred_test, ), '\\n')\n",
    "    print(f\"Jaccard Score: {jaccard_score(y_test, y_pred_test)}\")\n",
    "    print(f\"Log loss: {log_loss(y_test, y_pred_test)}\", '\\n')\n",
    "\n",
    "    # print other result about predicted data\n",
    "    return acc_test, acc_train, rec_test, rec_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"multinomial\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:100%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">6.1. MultinomialNB( )</p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:26.892743Z",
     "iopub.status.busy": "2022-11-13T19:42:26.892297Z",
     "iopub.status.idle": "2022-11-13T19:42:26.93554Z",
     "shell.execute_reply": "2022-11-13T19:42:26.934198Z",
     "shell.execute_reply.started": "2022-11-13T19:42:26.892672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# split train and test data by inital test_size=0.2\n",
    "# stratify used for considering class distribution in spliting data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:26.937553Z",
     "iopub.status.busy": "2022-11-13T19:42:26.937163Z",
     "iopub.status.idle": "2022-11-13T19:42:27.03687Z",
     "shell.execute_reply": "2022-11-13T19:42:27.035579Z",
     "shell.execute_reply.started": "2022-11-13T19:42:26.937521Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check cross validation on Multinomial model to estimate model performance (Accuracy)\n",
    "# use MinMaxScaler instead of StandardScaler for prevent negative number\n",
    "pipe1 = Pipeline([('scaler', MinMaxScaler()), ('clf', MultinomialNB())])\n",
    "Perform_cross_val(pipe1, k=10, x=x_train, y=y_train, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:27.038624Z",
     "iopub.status.busy": "2022-11-13T19:42:27.03827Z",
     "iopub.status.idle": "2022-11-13T19:42:27.14514Z",
     "shell.execute_reply": "2022-11-13T19:42:27.143851Z",
     "shell.execute_reply.started": "2022-11-13T19:42:27.038591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check cross validation on Multinomial model to estimate model performance (Recall)\n",
    "Perform_cross_val(pipe1, k=10, x=x_train, y=y_train, scoring='recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the obtained result, we expect our MultinomialNB model to have an accuracy close to or greater than 0.90 and low recall. Let's check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:27.147656Z",
     "iopub.status.busy": "2022-11-13T19:42:27.146586Z",
     "iopub.status.idle": "2022-11-13T19:42:27.694644Z",
     "shell.execute_reply": "2022-11-13T19:42:27.693406Z",
     "shell.execute_reply.started": "2022-11-13T19:42:27.147617Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create initial model with MultinomialNB algorithm\n",
    "acc_test_1_1, acc_train_1_1, rec_test_1_1, rec_train_1_1 = modeling(\n",
    "    clf=pipe1,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    test_size=0.2,\n",
    "    classes={'Not Accepted':0, 'Accepted':1},\n",
    "    model_name='MultinomialNB 1',\n",
    "    stratify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since not being able to identify a potential customer is the biggest loss, hence recall is the right metric to check the performance of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:27.697404Z",
     "iopub.status.busy": "2022-11-13T19:42:27.696934Z",
     "iopub.status.idle": "2022-11-13T19:42:27.703258Z",
     "shell.execute_reply": "2022-11-13T19:42:27.702373Z",
     "shell.execute_reply.started": "2022-11-13T19:42:27.697359Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Recall train: {rec_train_1_1}\")\n",
    "print(f\"Recall test: {rec_test_1_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected, the test accuracy obtained is close to the accuracy obtained from cross-validation. This model has correctly predicted almost all values with class 0, but it has performed extremely poorly in predicting class 1, which is due to the lack of data with class 1. Also, 95 people who accepted a personal loan were wrongly predicted, which is a relatively large number.\n",
    "\n",
    "Based on this, maybe other values of test size will improve the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:27.704693Z",
     "iopub.status.busy": "2022-11-13T19:42:27.704332Z",
     "iopub.status.idle": "2022-11-13T19:42:28.04349Z",
     "shell.execute_reply": "2022-11-13T19:42:28.041997Z",
     "shell.execute_reply.started": "2022-11-13T19:42:27.704656Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check improve model by change test size\n",
    "change_test_size(pipe1, x, y, 'MultinomialNB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So best model by MultinomialNB algorithm is the initail model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:28.047815Z",
     "iopub.status.busy": "2022-11-13T19:42:28.047378Z",
     "iopub.status.idle": "2022-11-13T19:42:28.063565Z",
     "shell.execute_reply": "2022-11-13T19:42:28.062326Z",
     "shell.execute_reply.started": "2022-11-13T19:42:28.047759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create a Dataframe for store accuracy and recall of best model for each algorithm\n",
    "best_model_test = pd.DataFrame({'Model':[], 'test_size':[], 'Test_Accuracy':[], 'Test_Recall':[]})\n",
    "best_model_train = pd.DataFrame({'Model':[], 'test_size':[], 'Train_Accuracy':[], 'Train_Recall':[]})\n",
    "# add best model and its accuracy and recall\n",
    "best_model_test.loc[len(best_model_test.index)] = [f\"MultinomialNB\", '0.2', acc_test_1_1, rec_test_1_1]\n",
    "best_model_train.loc[len(best_model_train.index)] = [f\"MultinomialNB\", '0.2', acc_train_1_1, rec_train_1_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"categorical\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:100%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">6.2. CategoricalNB( )</p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply this algorithm, all the features must be of category type, so it is necessary to create and save changes in the previous dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:28.065715Z",
     "iopub.status.busy": "2022-11-13T19:42:28.06524Z",
     "iopub.status.idle": "2022-11-13T19:42:28.083526Z",
     "shell.execute_reply": "2022-11-13T19:42:28.082674Z",
     "shell.execute_reply.started": "2022-11-13T19:42:28.06567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.Age.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the minimum and maximum ages are 23 and 67 respectively.\n",
    "\n",
    "üëâ The age will be divided into **5 age categories**:\n",
    "*  Below 30 y.o.\n",
    "*  30 - 39 y.o.\n",
    "*  40 - 49 y.o.\n",
    "*  50 - 59 y.o.\n",
    "*  Above 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:28.085305Z",
     "iopub.status.busy": "2022-11-13T19:42:28.084845Z",
     "iopub.status.idle": "2022-11-13T19:42:28.091215Z",
     "shell.execute_reply": "2022-11-13T19:42:28.090314Z",
     "shell.execute_reply.started": "2022-11-13T19:42:28.085259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:28.092585Z",
     "iopub.status.busy": "2022-11-13T19:42:28.092246Z",
     "iopub.status.idle": "2022-11-13T19:42:28.108203Z",
     "shell.execute_reply": "2022-11-13T19:42:28.107015Z",
     "shell.execute_reply.started": "2022-11-13T19:42:28.092556Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bin_age = [0, 29, 39, 49, 59, 70]\n",
    "category_age = ['<30s', '30s', '40s', '50s', '>50s']\n",
    "df2['Age_binned'] = pd.cut(df2['Age'], bins=bin_age, labels=category_age)\n",
    "df2 = df2.drop(['Age'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:28.110871Z",
     "iopub.status.busy": "2022-11-13T19:42:28.110347Z",
     "iopub.status.idle": "2022-11-13T19:42:28.12461Z",
     "shell.execute_reply": "2022-11-13T19:42:28.123094Z",
     "shell.execute_reply.started": "2022-11-13T19:42:28.110819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.Experience.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the minimum and maximum Experience are 0 and 43 respectively.\n",
    "\n",
    "üëâ The age will be divided into **5 Experience categories**:\n",
    "*  Below 10 y.o.\n",
    "*  10 - 19 y.o.\n",
    "*  20 - 29 y.o.\n",
    "*  30 - 39 y.o.\n",
    "*  Above 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:28.128844Z",
     "iopub.status.busy": "2022-11-13T19:42:28.128151Z",
     "iopub.status.idle": "2022-11-13T19:42:28.137721Z",
     "shell.execute_reply": "2022-11-13T19:42:28.136854Z",
     "shell.execute_reply.started": "2022-11-13T19:42:28.128776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bin_experience = [-1, 9, 19, 29, 39, 50]\n",
    "category_experience = ['<10s', '10s', '20s', '30s', '>30s']\n",
    "df2['Experience_binned'] = pd.cut(df2['Experience'], bins=bin_experience, labels=category_experience)\n",
    "df2 = df2.drop(['Experience'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:28.140213Z",
     "iopub.status.busy": "2022-11-13T19:42:28.139483Z",
     "iopub.status.idle": "2022-11-13T19:42:28.153344Z",
     "shell.execute_reply": "2022-11-13T19:42:28.152422Z",
     "shell.execute_reply.started": "2022-11-13T19:42:28.140169Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.Income.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the minimum and maximum Income are 0.67 and 18.67 respectively.\n",
    "\n",
    "üëâ The age will be divided into **4 Income categories**:\n",
    "*  Below 5 y.o.\n",
    "*  5 - 9 y.o.\n",
    "*  10 - 14 y.o.\n",
    "*  Above 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:28.155177Z",
     "iopub.status.busy": "2022-11-13T19:42:28.154636Z",
     "iopub.status.idle": "2022-11-13T19:42:28.164692Z",
     "shell.execute_reply": "2022-11-13T19:42:28.163752Z",
     "shell.execute_reply.started": "2022-11-13T19:42:28.155145Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bin_income = [0, 4, 9, 14, 20]\n",
    "category_income = ['<5s', '5s', '10s', '10>s']\n",
    "df2['Income_binned'] = pd.cut(df2['Income'], bins=bin_income, labels=category_income)\n",
    "df2 = df2.drop(['Income'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:28.167302Z",
     "iopub.status.busy": "2022-11-13T19:42:28.166249Z",
     "iopub.status.idle": "2022-11-13T19:42:28.184014Z",
     "shell.execute_reply": "2022-11-13T19:42:28.182857Z",
     "shell.execute_reply.started": "2022-11-13T19:42:28.167256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.CCAvg.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the minimum and maximum CCAvg are 0 and 10 respectively.\n",
    "\n",
    "üëâ The age will be divided into **5 CCAvg categories**:\n",
    "*  Below 2 y.o.\n",
    "*  2 - 3 y.o.\n",
    "*  4 - 5 y.o.\n",
    "*  6 - 7 y.o.\n",
    "*  Above 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:28.18648Z",
     "iopub.status.busy": "2022-11-13T19:42:28.18586Z",
     "iopub.status.idle": "2022-11-13T19:42:28.196279Z",
     "shell.execute_reply": "2022-11-13T19:42:28.195228Z",
     "shell.execute_reply.started": "2022-11-13T19:42:28.186446Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bin_CCAvg = [-1, 1, 3, 5, 7, 10]\n",
    "category_CCAvg = ['<2s', '2s', '4s', '6s', '>6s']\n",
    "df2['CCAvg_binned'] = pd.cut(df2['CCAvg'], bins=bin_CCAvg, labels=category_CCAvg)\n",
    "df2 = df2.drop(['CCAvg'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:28.198434Z",
     "iopub.status.busy": "2022-11-13T19:42:28.197588Z",
     "iopub.status.idle": "2022-11-13T19:42:28.210853Z",
     "shell.execute_reply": "2022-11-13T19:42:28.209757Z",
     "shell.execute_reply.started": "2022-11-13T19:42:28.198401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.Mortgage.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the minimum and maximum Mortgage are 0 and 635 respectively.\n",
    "\n",
    "üëâ The age will be divided into **9 Mortgage categories**:\n",
    "*  Below 50 y.o.\n",
    "*  50 - 99 y.o.\n",
    "*  100 - 149 y.o.\n",
    "*  150 - 199 y.o.\n",
    "*  200 - 249 y.o.\n",
    "*  250 - 299 y.o.\n",
    "*  300 - 349 y.o.\n",
    "*  350 - 399 y.o.\n",
    "*  Above 400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:28.212799Z",
     "iopub.status.busy": "2022-11-13T19:42:28.212344Z",
     "iopub.status.idle": "2022-11-13T19:42:28.22267Z",
     "shell.execute_reply": "2022-11-13T19:42:28.221863Z",
     "shell.execute_reply.started": "2022-11-13T19:42:28.212754Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bin_Mortgage = [-1, 49, 99, 149, 199, 249, 299, 349, 399, 700]\n",
    "category_Mortgage = ['<50s', '50s', '100s', '150s', '200s', '250s', '300s', '350s', '>350']\n",
    "df2['Mortgage_binned'] = pd.cut(df2['Mortgage'], bins=bin_Mortgage, labels=category_Mortgage)\n",
    "df2 = df2.drop(['Mortgage'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:28.22498Z",
     "iopub.status.busy": "2022-11-13T19:42:28.224361Z",
     "iopub.status.idle": "2022-11-13T19:42:28.254152Z",
     "shell.execute_reply": "2022-11-13T19:42:28.252887Z",
     "shell.execute_reply.started": "2022-11-13T19:42:28.224946Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# convert int64 type to category type because we want to use get dummies\n",
    "df2[df2.select_dtypes('int64').columns] = df2.select_dtypes('int64').astype('category')\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:28.256266Z",
     "iopub.status.busy": "2022-11-13T19:42:28.25564Z",
     "iopub.status.idle": "2022-11-13T19:42:28.268212Z",
     "shell.execute_reply": "2022-11-13T19:42:28.266871Z",
     "shell.execute_reply.started": "2022-11-13T19:42:28.256231Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T19:42:28.270634Z",
     "iopub.status.busy": "2022-11-13T19:42:28.26997Z",
     "iopub.status.idle": "2022-11-13T19:42:28.302859Z",
     "shell.execute_reply": "2022-11-13T19:42:28.301427Z",
     "shell.execute_reply.started": "2022-11-13T19:42:28.270598Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:07:31.727824Z",
     "iopub.status.busy": "2022-11-13T20:07:31.727395Z",
     "iopub.status.idle": "2022-11-13T20:07:31.770972Z",
     "shell.execute_reply": "2022-11-13T20:07:31.769813Z",
     "shell.execute_reply.started": "2022-11-13T20:07:31.72777Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# use get dummies\n",
    "df3 = pd.get_dummies(df2.drop('Personal Loan', axis=1))\n",
    "df3.insert(0, 'Personal Loan', df2['Personal Loan'])\n",
    "df3 = df3.astype('int64')\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use CategoricalNB, ComplementNB and BernoulliNB algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:07:54.618286Z",
     "iopub.status.busy": "2022-11-13T20:07:54.617887Z",
     "iopub.status.idle": "2022-11-13T20:07:54.629738Z",
     "shell.execute_reply": "2022-11-13T20:07:54.628681Z",
     "shell.execute_reply.started": "2022-11-13T20:07:54.618255Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# first define new x and y for new dataset:\n",
    "x2 = df3.drop('Personal Loan', axis=1)\n",
    "y2 = df3[['Personal Loan']].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:08:05.994764Z",
     "iopub.status.busy": "2022-11-13T20:08:05.994343Z",
     "iopub.status.idle": "2022-11-13T20:08:06.026818Z",
     "shell.execute_reply": "2022-11-13T20:08:06.025512Z",
     "shell.execute_reply.started": "2022-11-13T20:08:05.994729Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# split train and test data by inital test_size=0.2\n",
    "# stratify used for considering class distribution in spliting data\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.2, random_state=0, stratify=y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:07.076931Z",
     "iopub.status.busy": "2022-11-13T20:09:07.076486Z",
     "iopub.status.idle": "2022-11-13T20:09:07.234367Z",
     "shell.execute_reply": "2022-11-13T20:09:07.233156Z",
     "shell.execute_reply.started": "2022-11-13T20:09:07.076895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check cross validation on CategoricalNB model to estimate model performance (accuracy)\n",
    "pipe2 = Pipeline([('clf', CategoricalNB())])\n",
    "Perform_cross_val(pipe2, k=10, x=x_train2, y=y_train2, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:09.335782Z",
     "iopub.status.busy": "2022-11-13T20:09:09.334814Z",
     "iopub.status.idle": "2022-11-13T20:09:09.508813Z",
     "shell.execute_reply": "2022-11-13T20:09:09.507696Z",
     "shell.execute_reply.started": "2022-11-13T20:09:09.335727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check cross validation on CategoricalNB model to estimate model performance (recall)\n",
    "Perform_cross_val(pipe2, k=10, x=x_train2, y=y_train2, scoring='recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the obtained result, we expect our ComplementNB model to have an accuracy close to or greater than 0.932. Also, according to the average recall value obtained above, we expect that the recall of this model is better than the previous model. Let's check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:12.644986Z",
     "iopub.status.busy": "2022-11-13T20:09:12.644576Z",
     "iopub.status.idle": "2022-11-13T20:09:13.166626Z",
     "shell.execute_reply": "2022-11-13T20:09:13.165385Z",
     "shell.execute_reply.started": "2022-11-13T20:09:12.644954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create initial model with CategoricalNB\n",
    "acc_test_2_1, acc_train_2_1, rec_test_2_1, rec_train_2_1 = modeling(\n",
    "    clf=pipe2,\n",
    "    x=x2,\n",
    "    y=y2,\n",
    "    test_size=0.2,\n",
    "    classes={'Not Accepted':0, 'Accepted':1},\n",
    "    model_name='CategoricalNB 1',\n",
    "    stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:13.346114Z",
     "iopub.status.busy": "2022-11-13T20:09:13.344949Z",
     "iopub.status.idle": "2022-11-13T20:09:13.352778Z",
     "shell.execute_reply": "2022-11-13T20:09:13.351531Z",
     "shell.execute_reply.started": "2022-11-13T20:09:13.346055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Recall train: {rec_train_2_1}\")\n",
    "print(f\"Recall test: {rec_test_2_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy and recall obtained is the same as we expected. To improve models, other test size values are also checked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:14.915095Z",
     "iopub.status.busy": "2022-11-13T20:09:14.914673Z",
     "iopub.status.idle": "2022-11-13T20:09:15.233821Z",
     "shell.execute_reply": "2022-11-13T20:09:15.232655Z",
     "shell.execute_reply.started": "2022-11-13T20:09:14.915054Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check improve model by change test_size\n",
    "change_test_size(pipe2, x2, y2, 'CategoricalNB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the slight increase in the accuracy value, the recall value did not improve by changing the test size, so the initial CategoricalNB model is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So best model by CategoricalNB algorithm is the model by test_size = 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:15.237004Z",
     "iopub.status.busy": "2022-11-13T20:09:15.236248Z",
     "iopub.status.idle": "2022-11-13T20:09:15.251128Z",
     "shell.execute_reply": "2022-11-13T20:09:15.249473Z",
     "shell.execute_reply.started": "2022-11-13T20:09:15.236958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# add best model and its accuracy and recall\n",
    "best_model_test.loc[len(best_model_test.index)] = [f\"CategoricalNB\", '0.2', acc_test_2_1, rec_test_2_1]\n",
    "best_model_train.loc[len(best_model_train.index)] = [f\"CategoricalNB\", '0.2', acc_train_2_1, rec_train_2_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"complement\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:100%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">6.3. ComplementNB( )</p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:15.25458Z",
     "iopub.status.busy": "2022-11-13T20:09:15.253656Z",
     "iopub.status.idle": "2022-11-13T20:09:15.335161Z",
     "shell.execute_reply": "2022-11-13T20:09:15.333878Z",
     "shell.execute_reply.started": "2022-11-13T20:09:15.25453Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check cross validation on Complement model to estimate model performance (Accuracy)\n",
    "pipe3 = Pipeline([('clf', ComplementNB())])\n",
    "Perform_cross_val(pipe3, k=10, x=x_train2, y=y_train2, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:15.655844Z",
     "iopub.status.busy": "2022-11-13T20:09:15.654986Z",
     "iopub.status.idle": "2022-11-13T20:09:15.742013Z",
     "shell.execute_reply": "2022-11-13T20:09:15.740589Z",
     "shell.execute_reply.started": "2022-11-13T20:09:15.655779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check cross validation on Complement model to estimate model performance (Recall)\n",
    "Perform_cross_val(pipe3, k=10, x=x_train2, y=y_train2, scoring='recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the obtained result, we expect our ComplementNB model to have an accuracy close to or greater than 0.87 and better recall. Let's check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:19.737757Z",
     "iopub.status.busy": "2022-11-13T20:09:19.736921Z",
     "iopub.status.idle": "2022-11-13T20:09:20.293355Z",
     "shell.execute_reply": "2022-11-13T20:09:20.291868Z",
     "shell.execute_reply.started": "2022-11-13T20:09:19.737706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create initial model with ComplementlNB\n",
    "acc_test_3_1, acc_train_3_1, rec_test_3_1, rec_train_3_1 = modeling(\n",
    "    clf=pipe3,\n",
    "    x=x2,\n",
    "    y=y2,\n",
    "    test_size=0.2,\n",
    "    classes={'Not Accepted':0, 'Accepted':1},\n",
    "    model_name='ComplementNB 1',\n",
    "    stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:20.2985Z",
     "iopub.status.busy": "2022-11-13T20:09:20.297232Z",
     "iopub.status.idle": "2022-11-13T20:09:20.305307Z",
     "shell.execute_reply": "2022-11-13T20:09:20.303464Z",
     "shell.execute_reply.started": "2022-11-13T20:09:20.298438Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Recall train: {rec_train_3_1}\")\n",
    "print(f\"Recall test: {rec_test_3_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy obtained is almost the same as we expected, but overall the accuracy of the model has decreased and it is not as good as the multinomialNB model, but recall is important for us. To improve models, other test size values are also checked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:20.615304Z",
     "iopub.status.busy": "2022-11-13T20:09:20.614874Z",
     "iopub.status.idle": "2022-11-13T20:09:21.11149Z",
     "shell.execute_reply": "2022-11-13T20:09:21.110328Z",
     "shell.execute_reply.started": "2022-11-13T20:09:20.615262Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check improve model by change test_size\n",
    "change_test_size(pipe3, x2, y2, 'ComplementNB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the slight increase in the accuracy value, the recall value did not improve by changing the test size, so the initial ComplementNB model is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So best model by ComplementNB algorithm is the model by test_size = 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:21.1137Z",
     "iopub.status.busy": "2022-11-13T20:09:21.113366Z",
     "iopub.status.idle": "2022-11-13T20:09:21.126221Z",
     "shell.execute_reply": "2022-11-13T20:09:21.125057Z",
     "shell.execute_reply.started": "2022-11-13T20:09:21.11367Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# add best model and its accuracy and recall\n",
    "best_model_test.loc[len(best_model_test.index)] = [f\"ComplementNB\", '0.2', acc_test_3_1, rec_test_3_1]\n",
    "best_model_train.loc[len(best_model_train.index)] = [f\"ComplementNB\", '0.2', acc_train_3_1, rec_train_3_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bernoulli\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:100%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">6.4. BernoulliNB( )</p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:21.128133Z",
     "iopub.status.busy": "2022-11-13T20:09:21.12775Z",
     "iopub.status.idle": "2022-11-13T20:09:21.160919Z",
     "shell.execute_reply": "2022-11-13T20:09:21.159633Z",
     "shell.execute_reply.started": "2022-11-13T20:09:21.128102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# split train and test data by inital test_size=0.2\n",
    "# stratify used for considering class distribution in spliting data\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.2, random_state=0, stratify=y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:21.165042Z",
     "iopub.status.busy": "2022-11-13T20:09:21.164486Z",
     "iopub.status.idle": "2022-11-13T20:09:21.273546Z",
     "shell.execute_reply": "2022-11-13T20:09:21.272004Z",
     "shell.execute_reply.started": "2022-11-13T20:09:21.164994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check cross validation on BernoulliNB model to estimate model performance (Accuracy)\n",
    "pipe4 = Pipeline([('clf', BernoulliNB())])\n",
    "Perform_cross_val(pipe4, k=10, x=x_train2, y=y_train2, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:21.275313Z",
     "iopub.status.busy": "2022-11-13T20:09:21.27498Z",
     "iopub.status.idle": "2022-11-13T20:09:21.389221Z",
     "shell.execute_reply": "2022-11-13T20:09:21.388135Z",
     "shell.execute_reply.started": "2022-11-13T20:09:21.275283Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check cross validation on BernoulliNB model to estimate model performance (Recall)\n",
    "Perform_cross_val(pipe4, k=10, x=x_train2, y=y_train2, scoring='recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the obtained result, we expect our BernoulliNB model to have an accuracy close to or greater than 0.93 and the recall value is lower than the complementNB model. Let's check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:21.3909Z",
     "iopub.status.busy": "2022-11-13T20:09:21.390527Z",
     "iopub.status.idle": "2022-11-13T20:09:21.96185Z",
     "shell.execute_reply": "2022-11-13T20:09:21.960479Z",
     "shell.execute_reply.started": "2022-11-13T20:09:21.390868Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create initial model with BernoulliNB and test_size=0.2\n",
    "acc_test_4_1, acc_train_4_1, rec_test_4_1, rec_train_4_1 = modeling(\n",
    "    clf=pipe4,\n",
    "    x=x2,\n",
    "    y=y2,\n",
    "    test_size=0.2,\n",
    "    classes={'Not Accepted':0, 'Accepted':1},\n",
    "    model_name='BernoulliNB 1',\n",
    "    stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:21.964779Z",
     "iopub.status.busy": "2022-11-13T20:09:21.963906Z",
     "iopub.status.idle": "2022-11-13T20:09:21.971507Z",
     "shell.execute_reply": "2022-11-13T20:09:21.970303Z",
     "shell.execute_reply.started": "2022-11-13T20:09:21.964732Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Recall train: {rec_train_4_1}\")\n",
    "print(f\"Recall test: {rec_test_4_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy and recall obtained is the same as we expected. To improve models, other test size values are also checked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:21.976515Z",
     "iopub.status.busy": "2022-11-13T20:09:21.975468Z",
     "iopub.status.idle": "2022-11-13T20:09:22.534605Z",
     "shell.execute_reply": "2022-11-13T20:09:22.533605Z",
     "shell.execute_reply.started": "2022-11-13T20:09:21.976323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check imporve model by change test_size\n",
    "change_test_size(pipe4, x2, y2, 'BernoulliNB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the slight increase in the accuracy value, the recall value did not improve by changing the test size, so the initial CategoricalNB model is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So best model by BernoulliNB algorithm is the model by test_size = 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:22.537332Z",
     "iopub.status.busy": "2022-11-13T20:09:22.536844Z",
     "iopub.status.idle": "2022-11-13T20:09:22.550177Z",
     "shell.execute_reply": "2022-11-13T20:09:22.548837Z",
     "shell.execute_reply.started": "2022-11-13T20:09:22.537289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# add best model and its accuracy and recall\n",
    "best_model_test.loc[len(best_model_test.index)] = [f\"BernoulliNB\", '0.2', acc_test_4_1, rec_test_4_1]\n",
    "best_model_train.loc[len(best_model_train.index)] = [f\"BernoulliNB\", '0.2', acc_train_4_1, rec_train_4_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"logisitc\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:100%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">6.5. LogisitcRegression( )</p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, we will use our first dataset df and x and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:22.551946Z",
     "iopub.status.busy": "2022-11-13T20:09:22.551605Z",
     "iopub.status.idle": "2022-11-13T20:09:22.580888Z",
     "shell.execute_reply": "2022-11-13T20:09:22.579871Z",
     "shell.execute_reply.started": "2022-11-13T20:09:22.551915Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# split train and test data by inital test_size=0.2\n",
    "# stratify used for considering class distribution in spliting data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:22.583707Z",
     "iopub.status.busy": "2022-11-13T20:09:22.582811Z",
     "iopub.status.idle": "2022-11-13T20:09:23.661304Z",
     "shell.execute_reply": "2022-11-13T20:09:23.660195Z",
     "shell.execute_reply.started": "2022-11-13T20:09:22.583662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check cross validation on LogisticRegression model to estimate model performance (Accuracy)\n",
    "logreg = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(solver='newton-cg'))])\n",
    "Perform_cross_val(logreg, k=10, x=x_train, y=y_train, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:23.67103Z",
     "iopub.status.busy": "2022-11-13T20:09:23.666806Z",
     "iopub.status.idle": "2022-11-13T20:09:24.129581Z",
     "shell.execute_reply": "2022-11-13T20:09:24.128507Z",
     "shell.execute_reply.started": "2022-11-13T20:09:23.670976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check cross validation on LogisticRegression model to estimate model performance (Recall)\n",
    "Perform_cross_val(logreg, k=10, x=x_train, y=y_train, scoring='recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the obtained result, we expect our LogisticRegression model to have an high accuracy so far close to or greater than 0.95 but its recall lower than previous model. Let's check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:24.137684Z",
     "iopub.status.busy": "2022-11-13T20:09:24.134387Z",
     "iopub.status.idle": "2022-11-13T20:09:24.728277Z",
     "shell.execute_reply": "2022-11-13T20:09:24.727252Z",
     "shell.execute_reply.started": "2022-11-13T20:09:24.137629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create initial model with LogisticRegression and test_size=0.2\n",
    "acc_test_5_1, acc_train_5_1, rec_test_5_1, rec_train_5_1 = modeling(\n",
    "    clf=logreg,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    test_size=0.2,\n",
    "    classes={'Not Accepted':0, 'Accepted':1},\n",
    "    model_name='LogisticReg 1',\n",
    "    stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:24.729968Z",
     "iopub.status.busy": "2022-11-13T20:09:24.729568Z",
     "iopub.status.idle": "2022-11-13T20:09:24.735333Z",
     "shell.execute_reply": "2022-11-13T20:09:24.73418Z",
     "shell.execute_reply.started": "2022-11-13T20:09:24.729935Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Recall train: {rec_train_5_1}\")\n",
    "print(f\"Recall test: {rec_test_5_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy and recall obtained is the same as we expected. To improve models, other test size values are also checked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:24.739036Z",
     "iopub.status.busy": "2022-11-13T20:09:24.738677Z",
     "iopub.status.idle": "2022-11-13T20:09:25.446748Z",
     "shell.execute_reply": "2022-11-13T20:09:25.445198Z",
     "shell.execute_reply.started": "2022-11-13T20:09:24.739005Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# try to imporve model by changing test_size\n",
    "pipe5_1 = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression())])\n",
    "change_test_size(pipe5_1, x, y, 'LogisticReg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:25.455168Z",
     "iopub.status.busy": "2022-11-13T20:09:25.453929Z",
     "iopub.status.idle": "2022-11-13T20:09:36.344459Z",
     "shell.execute_reply": "2022-11-13T20:09:36.342983Z",
     "shell.execute_reply.started": "2022-11-13T20:09:25.455099Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# find best parameters for Logistic Regression estimator\n",
    "# define models and parameters\n",
    "model = LogisticRegression()\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "penalty = ['none','l2', 'l1']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='recall',error_score=0)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "x_norm_train = scaler.transform(x_train)\n",
    "x_norm_test = scaler.transform(x_test)\n",
    "grid_result = grid_search.fit(x_norm_train, y_train.ravel())\n",
    "# summarize results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"{mean} ({stdev}) with: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana;\">\n",
    "    üìåYou may see some warnings during the optimization for invalid configuration combinations. These can be safely ignored.\n",
    "</div>\n",
    "\n",
    "The results are summarized as follows:\n",
    "\n",
    "    Best: 0.6251012145748989 using {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:36.346922Z",
     "iopub.status.busy": "2022-11-13T20:09:36.346515Z",
     "iopub.status.idle": "2022-11-13T20:09:36.950588Z",
     "shell.execute_reply": "2022-11-13T20:09:36.949293Z",
     "shell.execute_reply.started": "2022-11-13T20:09:36.346884Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create better LogisticRegression model\n",
    "logreg2 = LogisticRegression(solver='liblinear', penalty='l1', C=1, n_jobs=-1)\n",
    "pipe5_2 = Pipeline([('scaler', StandardScaler()), ('clf', logreg2)])\n",
    "acc_test_5_2, acc_train_5_2, rec_test_5_2, rec_train_5_2 = modeling(\n",
    "    clf=pipe5_2,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    test_size=0.2,\n",
    "    classes={'Not Accepted':0, 'Accepted':1},\n",
    "    model_name='LogisticReg 2',\n",
    "    stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:36.953244Z",
     "iopub.status.busy": "2022-11-13T20:09:36.952271Z",
     "iopub.status.idle": "2022-11-13T20:09:36.95862Z",
     "shell.execute_reply": "2022-11-13T20:09:36.957531Z",
     "shell.execute_reply.started": "2022-11-13T20:09:36.953205Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Recall train: {rec_train_5_2}\")\n",
    "print(f\"Recall test: {rec_test_5_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:36.961061Z",
     "iopub.status.busy": "2022-11-13T20:09:36.95992Z",
     "iopub.status.idle": "2022-11-13T20:09:37.697438Z",
     "shell.execute_reply": "2022-11-13T20:09:37.695731Z",
     "shell.execute_reply.started": "2022-11-13T20:09:36.961023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check improve model by change test_size\n",
    "change_test_size(pipe5_2, x, y, 'LogisticReg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So best model by LogisticRegression algorithm is the model by test_size = 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:37.701405Z",
     "iopub.status.busy": "2022-11-13T20:09:37.700187Z",
     "iopub.status.idle": "2022-11-13T20:09:37.724001Z",
     "shell.execute_reply": "2022-11-13T20:09:37.722407Z",
     "shell.execute_reply.started": "2022-11-13T20:09:37.701336Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# add best model and its accuracy and recall\n",
    "best_model_test.loc[len(best_model_test.index)] = [f\"LogisticReg\", '0.2', acc_test_5_2, rec_test_5_2]\n",
    "best_model_train.loc[len(best_model_train.index)] = [f\"LogisticReg\", '0.2', acc_train_5_2, rec_train_5_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"knn\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:100%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">6.6. KNN: KNeighborsClassifier( ) </p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:37.728333Z",
     "iopub.status.busy": "2022-11-13T20:09:37.727032Z",
     "iopub.status.idle": "2022-11-13T20:09:37.775007Z",
     "shell.execute_reply": "2022-11-13T20:09:37.774042Z",
     "shell.execute_reply.started": "2022-11-13T20:09:37.728257Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def knn_model(x, y, Ks, test_size, show_plot=1, stratify=True):\n",
    "    \"\"\"fit knn algorithm, predict x_test and draw plots if you want\n",
    "    \n",
    "        x (DataFrame or array): features\n",
    "        y (DataFrame or array): target\n",
    "        test_size (float): parameter that use for split data to train and test set\n",
    "        show_plot (1 or any): for draw plots\n",
    "        \n",
    "        Retrun Accuracy_train and Accuracy_test\"\"\"\n",
    "\n",
    "    # split dataset   \n",
    "    if stratify:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=0, stratify=y)\n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=0)\n",
    "\n",
    "    print('-'*20, 'Shape', '-'*20)\n",
    "    print ('Train set:', x_train.shape,  y_train.shape)\n",
    "    print ('Test set:', x_test.shape,  y_test.shape, '\\n')\n",
    "\n",
    "    # initial values and constants\n",
    "    Ks = Ks\n",
    "    ACC_train = np.zeros((Ks))\n",
    "    ACC_test = np.zeros((Ks))\n",
    "    REC_train = np.zeros((Ks))\n",
    "    REC_test = np.zeros((Ks))\n",
    "\n",
    "    # for loop for find best k \n",
    "    for k in range(1,Ks+1):\n",
    "        # train model and predict\n",
    "        pipe = Pipeline([('scaler', StandardScaler()), ('clf', KNeighborsClassifier(n_neighbors=k))])\n",
    "        pipe.fit(x_train, y_train.ravel())\n",
    "        y_pred_train = pipe.predict(x_train)\n",
    "        y_pred_test = pipe.predict(x_test)\n",
    "        ACC_train[k-1] = accuracy_score(y_train, y_pred_train)\n",
    "        ACC_test[k-1] = accuracy_score(y_test, y_pred_test)\n",
    "        REC_train[k-1] = recall_score(y_train, y_pred_train)\n",
    "        REC_test[k-1] = recall_score(y_test, y_pred_test)\n",
    "\n",
    "    # draw plots\n",
    "    if show_plot == 1:    \n",
    "        x = list(range(1,Ks+1))\n",
    "        x_rev = x[::-1]\n",
    "\n",
    "        # Train Accuracy line\n",
    "        y1 = ACC_train\n",
    "        # Test Accuracy line\n",
    "        y2 = ACC_test\n",
    "        # Train Recall line\n",
    "        y3 = REC_train\n",
    "        # Test Recall line\n",
    "        y4 = REC_test\n",
    "\n",
    "        fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Accuracy\", \"Recall\"))\n",
    "        \n",
    "        # Train Accuracy plot (in 1st subplot)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, y=y1,\n",
    "            line_color='rgb(0,100,80)',\n",
    "            name='Train Accuracy',\n",
    "        ), row=1, col=1)\n",
    "\n",
    "        # Test Accuracy plot (in 1st subplot)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, y=y2,\n",
    "            line_color='rgb(255,140,0)',\n",
    "            name='Test Accuracy',\n",
    "        ), row=1, col=1)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # # Train Recall plot (in 2nd subplot)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, y=y3,\n",
    "            line_color='rgb(212, 31, 13)',\n",
    "            name='Train Recall',\n",
    "        ), row=1, col=2)\n",
    "\n",
    "        # Test Recall plot (in 2nd subplot)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, y=y4,\n",
    "            line_color='rgb(13, 109, 212)',\n",
    "            name='Test Recall',\n",
    "        ), row=1, col=2)\n",
    "\n",
    "        # Update xaxis properties\n",
    "        fig.update_xaxes(title_text=\"Number of Neighbors (k)\", row=1, col=1)\n",
    "        fig.update_xaxes(title_text=\"Number of Neighbors (k)\", row=1, col=2)\n",
    "\n",
    "        # Update yaxis properties\n",
    "        fig.update_yaxes(title_text=\"Accuracy\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Recall\", row=1, col=2)\n",
    "\n",
    "        fig.update_traces(mode='lines')\n",
    "        fig.update_layout(title_text=\"Accuracy and Recall of KNN models for all k\")\n",
    "        fig.show()\n",
    "\n",
    "    # print results\n",
    "    print( f\"The best train accuracy was {ACC_train.max()} with {ACC_train.argmax()+1}\") \n",
    "    print( f\"The best test accuracy was {ACC_test.max()} with {ACC_test.argmax()+1}\")\n",
    "    print( f\"The best train recall was {REC_train.max()} with {REC_train.argmax()+1}\")\n",
    "    print( f\"The best test recall was {REC_test.max()} with {REC_test.argmax()+1}\")\n",
    "    \n",
    "    return  ACC_test, ACC_train, REC_test, REC_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:37.777531Z",
     "iopub.status.busy": "2022-11-13T20:09:37.776437Z",
     "iopub.status.idle": "2022-11-13T20:09:37.808023Z",
     "shell.execute_reply": "2022-11-13T20:09:37.806865Z",
     "shell.execute_reply.started": "2022-11-13T20:09:37.777482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# split train and test data by inital test_size=0.2\n",
    "# stratify used for considering class distribution in spliting data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:37.814264Z",
     "iopub.status.busy": "2022-11-13T20:09:37.813878Z",
     "iopub.status.idle": "2022-11-13T20:09:38.196796Z",
     "shell.execute_reply": "2022-11-13T20:09:38.195545Z",
     "shell.execute_reply.started": "2022-11-13T20:09:37.814233Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check cross validation on KNN model to estimate model performance (Accuracy)\n",
    "operations = [('scaler', StandardScaler()), ('knn', KNeighborsClassifier())]\n",
    "pipe6_1 = Pipeline(operations)\n",
    "Perform_cross_val(pipe6_1, k=10, x=x_train, y=y_train, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:38.200142Z",
     "iopub.status.busy": "2022-11-13T20:09:38.198497Z",
     "iopub.status.idle": "2022-11-13T20:09:38.58599Z",
     "shell.execute_reply": "2022-11-13T20:09:38.584715Z",
     "shell.execute_reply.started": "2022-11-13T20:09:38.200072Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check cross validation on KNN model to estimate model performance (Recall)\n",
    "Perform_cross_val(pipe6_1, k=10, x=x_train, y=y_train, scoring='recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the obtained result, we expect our KNN model to have an accuracy close to or greater than 0.957. Let's check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:38.587781Z",
     "iopub.status.busy": "2022-11-13T20:09:38.587425Z",
     "iopub.status.idle": "2022-11-13T20:09:51.481652Z",
     "shell.execute_reply": "2022-11-13T20:09:51.480503Z",
     "shell.execute_reply.started": "2022-11-13T20:09:38.58775Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# find best k for knn model\n",
    "acc_test_6_1, acc_train_6_1, rec_test_6_1, rec_train_6_1 = knn_model(x, y, 30, 0.2, show_plot=1, stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:51.483326Z",
     "iopub.status.busy": "2022-11-13T20:09:51.482973Z",
     "iopub.status.idle": "2022-11-13T20:09:53.524269Z",
     "shell.execute_reply": "2022-11-13T20:09:53.523127Z",
     "shell.execute_reply.started": "2022-11-13T20:09:51.483294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check improve model by change test_size\n",
    "change_test_size(pipe6_1, x, y, 'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best value of k for the accuracy of the model is 3, but recall is important for us and for this, k is 1, but this value, as is known, causes the model to overfit. The best k for recall that performs best after k=1 and does not cause the model to overfit is k=3. (Because it is a classification problem, it is better to use even k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:53.526288Z",
     "iopub.status.busy": "2022-11-13T20:09:53.525953Z",
     "iopub.status.idle": "2022-11-13T20:09:54.483465Z",
     "shell.execute_reply": "2022-11-13T20:09:54.482086Z",
     "shell.execute_reply.started": "2022-11-13T20:09:53.526259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create better model on KNN algorithm by k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "pipe6_2 = Pipeline([('scaler', StandardScaler()), ('clf', knn)])\n",
    "acc_test_6_1, acc_train_6_1, rec_test_6_1, rec_train_6_1 = modeling(\n",
    "    clf=pipe6_2,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    test_size=0.2,\n",
    "    classes={'Not Accepted':0, 'Accepted':1},\n",
    "    model_name='KNN1',\n",
    "    stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:54.486089Z",
     "iopub.status.busy": "2022-11-13T20:09:54.485377Z",
     "iopub.status.idle": "2022-11-13T20:09:54.492735Z",
     "shell.execute_reply": "2022-11-13T20:09:54.491502Z",
     "shell.execute_reply.started": "2022-11-13T20:09:54.48604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Recall train: {rec_train_6_1}\")\n",
    "print(f\"Recall test: {rec_test_6_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:09:54.495323Z",
     "iopub.status.busy": "2022-11-13T20:09:54.494639Z",
     "iopub.status.idle": "2022-11-13T20:11:45.029417Z",
     "shell.execute_reply": "2022-11-13T20:11:45.027809Z",
     "shell.execute_reply.started": "2022-11-13T20:09:54.495287Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# knn parameter tuning with gridsearch\n",
    "kValues = list(range(3, 31, 2))\n",
    "weights = ['uniform','distance']\n",
    "algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "p = [1,2]\n",
    "param_grid = dict(knn__n_neighbors=kValues, knn__weights=weights, knn__algorithm=algorithm, knn__p=p)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)\n",
    "classifier = GridSearchCV(pipe6_1, param_grid, cv=10, scoring='recall')\n",
    "classifier.fit(x_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:11:45.031943Z",
     "iopub.status.busy": "2022-11-13T20:11:45.03102Z",
     "iopub.status.idle": "2022-11-13T20:11:45.05256Z",
     "shell.execute_reply": "2022-11-13T20:11:45.0518Z",
     "shell.execute_reply.started": "2022-11-13T20:11:45.031908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results1 = classifier.best_estimator_.get_params()\n",
    "df_results1 = pd.DataFrame(results1).T.rename(columns={0: \"Values1\", 1: \"Values2\"})\n",
    "df_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:11:45.056814Z",
     "iopub.status.busy": "2022-11-13T20:11:45.056436Z",
     "iopub.status.idle": "2022-11-13T20:11:45.095467Z",
     "shell.execute_reply": "2022-11-13T20:11:45.094248Z",
     "shell.execute_reply.started": "2022-11-13T20:11:45.05676Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_results2 = pd.DataFrame(classifier.cv_results_)\n",
    "df_results2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above tables, the best model is a model with n_neighbors = 3, P = 2, algorithm = auto and weights = distance that is a default model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So best model by KNN algorithm is the model by test_size = 0.2 and k=3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:11:45.097015Z",
     "iopub.status.busy": "2022-11-13T20:11:45.096679Z",
     "iopub.status.idle": "2022-11-13T20:11:45.110995Z",
     "shell.execute_reply": "2022-11-13T20:11:45.109879Z",
     "shell.execute_reply.started": "2022-11-13T20:11:45.096987Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# add best model and its accuracy and recall\n",
    "best_model_test.loc[len(best_model_test.index)] = [f\"KNN (k=3)\", '0.2', acc_test_6_1, rec_test_6_1]\n",
    "best_model_train.loc[len(best_model_train.index)] = [f\"KNN (k=3)\", '0.2', acc_train_6_1, rec_train_6_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dt\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:100%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">6.7. Decision Tree </p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:11:45.112846Z",
     "iopub.status.busy": "2022-11-13T20:11:45.112461Z",
     "iopub.status.idle": "2022-11-13T20:11:45.143081Z",
     "shell.execute_reply": "2022-11-13T20:11:45.142029Z",
     "shell.execute_reply.started": "2022-11-13T20:11:45.112783Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:11:45.145356Z",
     "iopub.status.busy": "2022-11-13T20:11:45.144724Z",
     "iopub.status.idle": "2022-11-13T20:11:45.254947Z",
     "shell.execute_reply": "2022-11-13T20:11:45.253716Z",
     "shell.execute_reply.started": "2022-11-13T20:11:45.145319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check cross validation on DT model to estimate model performance (Accuracy)\n",
    "operations = [('DTs', DecisionTreeClassifier(max_depth=3))]\n",
    "pipe7_1 = Pipeline(operations)\n",
    "Perform_cross_val(pipe7_1, k=10, x=x_train, y=y_train, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:11:45.257616Z",
     "iopub.status.busy": "2022-11-13T20:11:45.256861Z",
     "iopub.status.idle": "2022-11-13T20:11:45.363523Z",
     "shell.execute_reply": "2022-11-13T20:11:45.36222Z",
     "shell.execute_reply.started": "2022-11-13T20:11:45.257581Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check cross validation on DT model to estimate model performance (Recall)\n",
    "Perform_cross_val(pipe7_1, k=10, x=x_train, y=y_train, scoring='recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results obtained above, we expect the model to have an accuracy of around 98% and its recall to be high. Let's check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:11:45.366306Z",
     "iopub.status.busy": "2022-11-13T20:11:45.365608Z",
     "iopub.status.idle": "2022-11-13T20:11:45.78949Z",
     "shell.execute_reply": "2022-11-13T20:11:45.788262Z",
     "shell.execute_reply.started": "2022-11-13T20:11:45.366259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create initial DTs model without pruning\n",
    "dts = DecisionTreeClassifier(random_state=0)\n",
    "pipe7_1 = Pipeline([('scaler', StandardScaler()), ('clf', dts)])\n",
    "acc_test_7_1, acc_train_7_1, rec_test_7_1, rec_train_7_1 = modeling(\n",
    "    clf=pipe7_1,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    test_size=0.2,\n",
    "    classes={'Not Accepted':0, 'Accepted':1},\n",
    "    model_name='DT 1',\n",
    "    stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:11:45.791664Z",
     "iopub.status.busy": "2022-11-13T20:11:45.791217Z",
     "iopub.status.idle": "2022-11-13T20:11:45.798488Z",
     "shell.execute_reply": "2022-11-13T20:11:45.797263Z",
     "shell.execute_reply.started": "2022-11-13T20:11:45.791611Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Train Accuracy: {acc_train_7_1}\")\n",
    "print(f\"Test Accuracy: {acc_test_7_1}\")\n",
    "print(f\"Train Recall: {rec_train_7_1}\")\n",
    "print(f\"Test Recall: {rec_test_7_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:11:45.800299Z",
     "iopub.status.busy": "2022-11-13T20:11:45.799969Z",
     "iopub.status.idle": "2022-11-13T20:11:45.827737Z",
     "shell.execute_reply": "2022-11-13T20:11:45.826423Z",
     "shell.execute_reply.started": "2022-11-13T20:11:45.80027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(x_train,y_train.ravel())\n",
    "y_train_predicted=clf.predict(x_train)\n",
    "y_test_predicted=clf.predict(x_test)\n",
    "print(f\"Train Accuracy: {accuracy_score(y_train,y_train_predicted)}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test,y_test_predicted)}\")\n",
    "print(f\"Train Recall: {recall_score(y_train,y_train_predicted)}\")\n",
    "print(f\"Test Recall: {recall_score(y_test,y_test_predicted)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:11:45.829702Z",
     "iopub.status.busy": "2022-11-13T20:11:45.829153Z",
     "iopub.status.idle": "2022-11-13T20:11:52.50204Z",
     "shell.execute_reply": "2022-11-13T20:11:52.50062Z",
     "shell.execute_reply.started": "2022-11-13T20:11:45.829643Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# visualizing tree\n",
    "from sklearn import tree\n",
    "feature_names = x.columns\n",
    "target_names = ['0', '1']\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "dt1 = DecisionTreeClassifier(random_state=0)\n",
    "dt1.fit(x_train,y_train.ravel())\n",
    "plot = tree.plot_tree(\n",
    "    dt1,\n",
    "    feature_names = feature_names,\n",
    "    class_names = target_names,\n",
    "    filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the obtained result, our model is overfitting and our tree has many rules. This is a common problem in decision trees. To solve this problem, we use pruning techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:11:52.504935Z",
     "iopub.status.busy": "2022-11-13T20:11:52.503825Z",
     "iopub.status.idle": "2022-11-13T20:14:14.324186Z",
     "shell.execute_reply": "2022-11-13T20:14:14.322726Z",
     "shell.execute_reply.started": "2022-11-13T20:11:52.504894Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Grid of parameters to choose from\n",
    "grid_param={\"criterion\":[\"gini\",\"entropy\"],\n",
    "             \"max_depth\":range(2,10,1),\n",
    "             \"min_samples_leaf\":range(1,15,1),\n",
    "             \"min_samples_split\":range(2,20,1) \n",
    "            }\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "grid_search=GridSearchCV(estimator=dt1,param_grid=grid_param,cv=cv,n_jobs=-1)\n",
    "grid_search.fit(x_train,y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:14.32609Z",
     "iopub.status.busy": "2022-11-13T20:14:14.325736Z",
     "iopub.status.idle": "2022-11-13T20:14:14.331199Z",
     "shell.execute_reply": "2022-11-13T20:14:14.330227Z",
     "shell.execute_reply.started": "2022-11-13T20:14:14.326058Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:14.333143Z",
     "iopub.status.busy": "2022-11-13T20:14:14.332504Z",
     "iopub.status.idle": "2022-11-13T20:14:37.18495Z",
     "shell.execute_reply": "2022-11-13T20:14:37.181595Z",
     "shell.execute_reply.started": "2022-11-13T20:14:14.333108Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dt2=DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=14,\n",
    "    min_samples_split=2,\n",
    "    splitter='random'\n",
    "    )\n",
    "dt2.fit(x_train,y_train.ravel())\n",
    "plt.figure(figsize=(20,12), dpi=1000)\n",
    "plot = tree.plot_tree(\n",
    "    dt2,\n",
    "    feature_names = feature_names,\n",
    "    class_names = target_names,\n",
    "    filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:37.189615Z",
     "iopub.status.busy": "2022-11-13T20:14:37.188927Z",
     "iopub.status.idle": "2022-11-13T20:14:37.211461Z",
     "shell.execute_reply": "2022-11-13T20:14:37.209868Z",
     "shell.execute_reply.started": "2022-11-13T20:14:37.189518Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check Accuracy, Recanll and overfitting\n",
    "y_predicted_train= dt2.predict(x_train)\n",
    "y_predicted_test = dt2.predict(x_test)\n",
    "print(f\"Train Accuracy: {accuracy_score(y_train, y_predicted_train)}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_predicted_test)}\")\n",
    "print(f\"Train Recall: {recall_score(y_train, y_predicted_train)}\")\n",
    "print(f\"Test Recall: {recall_score(y_test, y_predicted_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is not overfit and the obtained results show high accuracy and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:37.213602Z",
     "iopub.status.busy": "2022-11-13T20:14:37.213203Z",
     "iopub.status.idle": "2022-11-13T20:14:37.511521Z",
     "shell.execute_reply": "2022-11-13T20:14:37.510253Z",
     "shell.execute_reply.started": "2022-11-13T20:14:37.213567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "importances = dt2.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='green', align='center')\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:37.523141Z",
     "iopub.status.busy": "2022-11-13T20:14:37.52203Z",
     "iopub.status.idle": "2022-11-13T20:14:37.838985Z",
     "shell.execute_reply": "2022-11-13T20:14:37.837597Z",
     "shell.execute_reply.started": "2022-11-13T20:14:37.523091Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_predicted_test)\n",
    "plot_confusion_matrix2(cm=cm, classes={'Not Accepted':0, 'Accepted':1}, )\n",
    "print(classification_report(y_test, y_predicted_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- According to the figure above, as seen in the EDA section, the two features Education and Income have the most effect and importance.\n",
    "\n",
    "- Important feature is Education, Income, Family, CCAvg, Securities Account, Online, Personal Loan\n",
    "\n",
    "- Obtained recall is good ÿ∞ut the model still incorrectly predicted 18 people who accepted the loan. Let's see if this value can be reduced or not:\n",
    "\n",
    "Now we use post-pruning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:37.842192Z",
     "iopub.status.busy": "2022-11-13T20:14:37.84168Z",
     "iopub.status.idle": "2022-11-13T20:14:37.862571Z",
     "shell.execute_reply": "2022-11-13T20:14:37.86133Z",
     "shell.execute_reply.started": "2022-11-13T20:14:37.842133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "path = dt1.cost_complexity_pruning_path(x_train, y_train)\n",
    "#path variable gives two things ccp_alphas and impurities\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "print(\"ccp alpha wil give list of values :\",ccp_alphas)\n",
    "print(\"\\n\")\n",
    "print(\"Impurities in Decision Tree :\",impurities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:37.864393Z",
     "iopub.status.busy": "2022-11-13T20:14:37.86398Z",
     "iopub.status.idle": "2022-11-13T20:14:38.140279Z",
     "shell.execute_reply": "2022-11-13T20:14:38.13907Z",
     "shell.execute_reply.started": "2022-11-13T20:14:37.86436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train a decision tree using the effective alphas\n",
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(x_train, y_train.ravel())\n",
    "    clfs.append(clf)\n",
    "print(\n",
    "    \"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n",
    "        clfs[-1].tree_.node_count, ccp_alphas[-1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:38.142416Z",
     "iopub.status.busy": "2022-11-13T20:14:38.141974Z",
     "iopub.status.idle": "2022-11-13T20:14:38.454692Z",
     "shell.execute_reply": "2022-11-13T20:14:38.453377Z",
     "shell.execute_reply.started": "2022-11-13T20:14:38.142382Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualizing the Recall score for train and test set:\n",
    "\n",
    "train_scores = [recall_score(y_train, clf.predict(x_train)) for clf in clfs]\n",
    "test_scores = [recall_score(y_test, clf.predict(x_test)) for clf in clfs]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ccp_alphas, y=train_scores, name='Train Recall', mode='lines+markers', line={\"shape\": 'hv'}))\n",
    "fig.add_trace(go.Scatter(x=ccp_alphas, y=test_scores, name='Test Recall', mode='lines+markers', line={\"shape\": 'hv'}))\n",
    "fig.update_layout(\n",
    "    xaxis_title='ccp_alphas',\n",
    "    yaxis_title='Recall',\n",
    "    title='Recall vs alpha for training and testing sets',\n",
    "    template='seaborn')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best result that is not tend to overfit will obtain by ccp_alpha = 0.002868053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:38.45684Z",
     "iopub.status.busy": "2022-11-13T20:14:38.456357Z",
     "iopub.status.idle": "2022-11-13T20:14:39.465362Z",
     "shell.execute_reply": "2022-11-13T20:14:39.46444Z",
     "shell.execute_reply.started": "2022-11-13T20:14:38.456779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create better Decision Tree (Post_pruning)\n",
    "dt3 = DecisionTreeClassifier(random_state=0, ccp_alpha=0.002868053)\n",
    "dt3.fit(x_train,y_train.ravel())\n",
    "fig = plt.figure(figsize=(10,10), dpi=100)\n",
    "plot = tree.plot_tree(\n",
    "    dt3,\n",
    "    feature_names = feature_names,\n",
    "    class_names = target_names,\n",
    "    filled=True)\n",
    "\n",
    "# for save tree plot\n",
    "# fig.savefig('Tree.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:39.466648Z",
     "iopub.status.busy": "2022-11-13T20:14:39.466333Z",
     "iopub.status.idle": "2022-11-13T20:14:39.471755Z",
     "shell.execute_reply": "2022-11-13T20:14:39.470498Z",
     "shell.execute_reply.started": "2022-11-13T20:14:39.466619Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# for save decsition tree threshold in file\n",
    "# text_representation = tree.export_text(dt3)\n",
    "# with open( \"decision_tree.log\", \"w\") as file:\n",
    "#     file.write(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:39.473832Z",
     "iopub.status.busy": "2022-11-13T20:14:39.473408Z",
     "iopub.status.idle": "2022-11-13T20:14:39.496472Z",
     "shell.execute_reply": "2022-11-13T20:14:39.494839Z",
     "shell.execute_reply.started": "2022-11-13T20:14:39.473774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print results for check overfit\n",
    "y_predicted_train= dt3.predict(x_train)\n",
    "y_predicted_test = dt3.predict(x_test)\n",
    "print(f\"Train Accuracy: {accuracy_score(y_train, y_predicted_train)}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_predicted_test)}\")\n",
    "print(f\"Train Recall: {recall_score(y_train, y_predicted_train)}\")\n",
    "print(f\"Test Recall: {recall_score(y_test, y_predicted_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:39.498379Z",
     "iopub.status.busy": "2022-11-13T20:14:39.498038Z",
     "iopub.status.idle": "2022-11-13T20:14:39.763251Z",
     "shell.execute_reply": "2022-11-13T20:14:39.76192Z",
     "shell.execute_reply.started": "2022-11-13T20:14:39.49835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# find important features\n",
    "importances = dt3.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='green', align='center')\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drawn plot helps us to understand which features are less important and can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:39.765128Z",
     "iopub.status.busy": "2022-11-13T20:14:39.764726Z",
     "iopub.status.idle": "2022-11-13T20:14:40.274558Z",
     "shell.execute_reply": "2022-11-13T20:14:40.273608Z",
     "shell.execute_reply.started": "2022-11-13T20:14:39.765095Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create better DTs model and draw plots\n",
    "pipe7_2 = Pipeline([('scaler', StandardScaler()), ('clf', dt3)])\n",
    "acc_test_7_2, acc_train_7_2, rec_test_7_2, rec_train_7_2 = modeling(\n",
    "    clf=pipe7_2,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    test_size=0.2,\n",
    "    classes={'Not Accepted':0, 'Accepted':1},\n",
    "    model_name='DT 2',\n",
    "    stratify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice result üòç !!!\n",
    "\n",
    "This Decision tree model that obtained by post pruning has given us best recall scores on data with 91.7% accuracy.\n",
    "\n",
    "We obtained very good result that is not overfit and the model has wrongly predicted only 8 people who accepted the loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:40.276812Z",
     "iopub.status.busy": "2022-11-13T20:14:40.27576Z",
     "iopub.status.idle": "2022-11-13T20:14:40.565148Z",
     "shell.execute_reply": "2022-11-13T20:14:40.563759Z",
     "shell.execute_reply.started": "2022-11-13T20:14:40.276755Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check improve model by change test_size\n",
    "change_test_size(pipe7_2, x, y, 'DT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So best model by Decision Tree algorithm is the model by test_size = 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:40.567023Z",
     "iopub.status.busy": "2022-11-13T20:14:40.566619Z",
     "iopub.status.idle": "2022-11-13T20:14:40.581113Z",
     "shell.execute_reply": "2022-11-13T20:14:40.579805Z",
     "shell.execute_reply.started": "2022-11-13T20:14:40.566988Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# add best model and its accuracy and recall\n",
    "best_model_test.loc[len(best_model_test.index)] = [f\"Decision Tree\", '0.2', acc_test_7_2, rec_test_7_2]\n",
    "best_model_train.loc[len(best_model_train.index)] = [f\"Decision Tree\", '0.2', acc_train_7_2, rec_train_7_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rf\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:100%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">6.8. Random Forest </p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:40.582822Z",
     "iopub.status.busy": "2022-11-13T20:14:40.582351Z",
     "iopub.status.idle": "2022-11-13T20:14:40.619231Z",
     "shell.execute_reply": "2022-11-13T20:14:40.618041Z",
     "shell.execute_reply.started": "2022-11-13T20:14:40.582759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# split train and test data by inital test_size=0.2\n",
    "# stratify used for considering class distribution in spliting data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:40.621353Z",
     "iopub.status.busy": "2022-11-13T20:14:40.620921Z",
     "iopub.status.idle": "2022-11-13T20:14:44.328229Z",
     "shell.execute_reply": "2022-11-13T20:14:44.327332Z",
     "shell.execute_reply.started": "2022-11-13T20:14:40.62131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check cross validation on Random Forest model to estimate model performance (Accuracy)\n",
    "operations = [('RF', RandomForestClassifier())]\n",
    "pipe8_1 = Pipeline(operations)\n",
    "Perform_cross_val(pipe8_1, k=10, x=x_train, y=y_train, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:44.329927Z",
     "iopub.status.busy": "2022-11-13T20:14:44.329281Z",
     "iopub.status.idle": "2022-11-13T20:14:48.036707Z",
     "shell.execute_reply": "2022-11-13T20:14:48.035573Z",
     "shell.execute_reply.started": "2022-11-13T20:14:44.329888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check cross validation on RandomForest model to estimate model performance (Recall)\n",
    "Perform_cross_val(pipe8_1, k=10, x=x_train, y=y_train, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:48.039186Z",
     "iopub.status.busy": "2022-11-13T20:14:48.038395Z",
     "iopub.status.idle": "2022-11-13T20:14:49.054065Z",
     "shell.execute_reply": "2022-11-13T20:14:49.052746Z",
     "shell.execute_reply.started": "2022-11-13T20:14:48.039141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create initial RF model without pruning\n",
    "rf = RandomForestClassifier()\n",
    "pipe8_1 = Pipeline([('scaler', StandardScaler()), ('clf', rf)])\n",
    "acc_test_8_1, acc_train_8_1, rec_test_8_1, rec_train_8_1 = modeling(\n",
    "    clf=pipe8_1,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    test_size=0.2,\n",
    "    classes={'Not Accepted':0, 'Accepted':1},\n",
    "    model_name='RF 1',\n",
    "    stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:49.056297Z",
     "iopub.status.busy": "2022-11-13T20:14:49.055939Z",
     "iopub.status.idle": "2022-11-13T20:14:49.062216Z",
     "shell.execute_reply": "2022-11-13T20:14:49.061239Z",
     "shell.execute_reply.started": "2022-11-13T20:14:49.056264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check accuracy, recall and overfitting\n",
    "print(f\"Train Accuracy: {acc_train_8_1}\")\n",
    "print(f\"Test Accuracy: {acc_test_8_1}\")\n",
    "print(f\"Train Recall: {rec_train_8_1}\")\n",
    "print(f\"Test Recall: {rec_test_8_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the model tends to overfit here as well, so to solve this problem, we perform parameter tuning for RF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-11-13T20:14:49.063647Z",
     "iopub.status.busy": "2022-11-13T20:14:49.063303Z",
     "iopub.status.idle": "2022-11-13T20:16:31.29Z",
     "shell.execute_reply": "2022-11-13T20:16:31.288765Z",
     "shell.execute_reply.started": "2022-11-13T20:14:49.063615Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# parameter tuning by loops instead grid search because \n",
    "# gridsearch is very expensive and Time-consuming for this dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import arange\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# get a list of models to evaluate \n",
    "# explore random forest bootstrap sample size\n",
    "def get_models1():\n",
    "\tprint(\"Explore random forest bootstrap sample size\")\n",
    "\tmodels = dict()\n",
    "\t# explore ratios from 10% to 100% in 10% increments\n",
    "\tfor i in arange(0.1, 1.1, 0.1):\n",
    "\t\tkey = f'{i:.1f}'\n",
    "\t\t# set max_samples=None to use 100%\n",
    "\t\tif i == 1.0:\n",
    "\t\t\ti = None\n",
    "\t\tmodels[key] = RandomForestClassifier(max_samples=i)\n",
    "\treturn models\n",
    "\n",
    "# get a list of models to evaluate\n",
    "# explore random forest number of features effect\n",
    "def get_models2():\n",
    "\tprint(\"Explore random forest number of features effect\")\n",
    "\tmodels = dict()\n",
    "\t# explore number of features from 1 to 7\n",
    "\tfor i in range(1,8):\n",
    "\t\tmodels[str(i)] = RandomForestClassifier(max_features=i)\n",
    "\treturn models\n",
    "\n",
    "# get a list of models to evaluate\n",
    "# explore random forest tree depth effect\n",
    "def get_models3():\n",
    "\tprint(\"Explore random forest tree depth effect\")\n",
    "\tmodels = dict()\n",
    "\t# consider tree depths from 1 to 7 and None=full\n",
    "\tdepths = [i for i in range(1,10)] + [None]\n",
    "\tfor n in depths:\n",
    "\t\tmodels[str(n)] = RandomForestClassifier(max_depth=n)\n",
    "\treturn models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model and collect the results\n",
    "\tscores = cross_val_score(model, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    " \n",
    "for func in [get_models1, get_models2, get_models3]:\n",
    "\t# get the models to evaluate\n",
    "\tmodels = func()\n",
    "\t# evaluate the models and store results\n",
    "\tresults, names = list(), list()\n",
    "\tfor name, model in models.items():\n",
    "\t\t# evaluate the model\n",
    "\t\tscores = evaluate_model(model, x_train, y_train)\n",
    "\t\t# store the results\n",
    "\t\tresults.append(scores)\n",
    "\t\tnames.append(name)\n",
    "\t\t# summarize the performance along the way\n",
    "\t\tprint(f\">{name:s}, mean:{mean(scores):.3f}, ste:{std(scores):.3f}\")\n",
    "\t# plot model performance for comparison\n",
    "\tplt.boxplot(results, labels=names, showmeans=True)\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana;\">\n",
    "    üìåYou may see some warnings during the optimization for invalid configuration combinations. These can be safely ignored.\n",
    "</div>\n",
    "\n",
    "The results are summarized as follows:\n",
    "\n",
    "    Explore random forest bootstrap sample size\n",
    "    >0.1, mean:0.763, ste:0.068\n",
    "    >0.2, mean:0.824, ste:0.060\n",
    "    >0.3, mean:0.850, ste:0.049\n",
    "    >0.4, mean:0.859, ste:0.053\n",
    "    >0.5, mean:0.867, ste:0.042\n",
    "    >0.6, mean:0.867, ste:0.048\n",
    "    >0.7, mean:0.876, ste:0.048\n",
    "    >0.8, mean:0.879, ste:0.050\n",
    "    >0.9, mean:0.878, ste:0.043\n",
    "    >1.0, mean:0.877, ste:0.047\n",
    "<center><img src='https://i.postimg.cc/W4VN67Hw/11.png' height=100px width=450px></center><br>\n",
    "\n",
    "    Explore random forest number of features effect\n",
    "    >1, mean:0.778, ste:0.061\n",
    "    >2, mean:0.866, ste:0.050\n",
    "    >3, mean:0.882, ste:0.047\n",
    "    >4, mean:0.885, ste:0.044\n",
    "    >5, mean:0.896, ste:0.035\n",
    "    >6, mean:0.899, ste:0.039\n",
    "    >7, mean:0.896, ste:0.038\n",
    "<center><img src='https://i.postimg.cc/ydY728BJ/12.png' height=100px width=450px></center><br>\n",
    "\n",
    "    Explore random forest tree depth effect\n",
    "    >1, mean:0.000, ste:0.000\n",
    "    >2, mean:0.119, ste:0.061\n",
    "    >3, mean:0.437, ste:0.086\n",
    "    >4, mean:0.658, ste:0.080\n",
    "    >5, mean:0.801, ste:0.059\n",
    "    >6, mean:0.840, ste:0.054\n",
    "    >7, mean:0.865, ste:0.052\n",
    "    >8, mean:0.869, ste:0.042\n",
    "    >9, mean:0.879, ste:0.044\n",
    "    >None, mean:0.877, ste:0.042\n",
    "<center><img src='https://i.postimg.cc/RhW4VpW4/13.png' height=100px width=450px></center><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can see that by max_sample=None, max_features=7, max_depth=None we have best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:16:31.292906Z",
     "iopub.status.busy": "2022-11-13T20:16:31.292087Z",
     "iopub.status.idle": "2022-11-13T20:16:32.444848Z",
     "shell.execute_reply": "2022-11-13T20:16:32.443517Z",
     "shell.execute_reply.started": "2022-11-13T20:16:31.29286Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create initial RF model without pruning\n",
    "rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    n_estimators=100,\n",
    "    max_samples=None,\n",
    "    max_features=7,\n",
    "    max_depth=None,\n",
    "    class_weight='balanced_subsample',)\n",
    "pipe8_2 = Pipeline([('scaler', StandardScaler()), ('clf', rf)])\n",
    "acc_test_8_2, acc_train_8_2, rec_test_8_2, rec_train_8_2 = modeling(\n",
    "    clf=pipe8_2,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    test_size=0.2,\n",
    "    classes={'Not Accepted':0, 'Accepted':1},\n",
    "    model_name='RF 2',\n",
    "    stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:16:32.447431Z",
     "iopub.status.busy": "2022-11-13T20:16:32.446954Z",
     "iopub.status.idle": "2022-11-13T20:16:32.454594Z",
     "shell.execute_reply": "2022-11-13T20:16:32.453353Z",
     "shell.execute_reply.started": "2022-11-13T20:16:32.447386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Train Accuracy: {acc_train_8_2}\")\n",
    "print(f\"Test Accuracy: {acc_test_8_2}\")\n",
    "print(f\"Train Recall: {rec_train_8_2}\")\n",
    "print(f\"Test Recall: {rec_test_8_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, the model tends to overfitting. So we change some of parameter to prevent overfitting and get the best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:16:32.456728Z",
     "iopub.status.busy": "2022-11-13T20:16:32.456356Z",
     "iopub.status.idle": "2022-11-13T20:16:33.995022Z",
     "shell.execute_reply": "2022-11-13T20:16:33.993769Z",
     "shell.execute_reply.started": "2022-11-13T20:16:32.456694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create initial RF model without pruning\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    n_estimators=150,\n",
    "    max_samples=None,\n",
    "    max_features=7,\n",
    "    max_depth=4,\n",
    "    class_weight='balanced_subsample',\n",
    "    oob_score=True\n",
    ")\n",
    "pipe8_3 = Pipeline([('scaler', StandardScaler()), ('clf', rf)])\n",
    "acc_test_8_3, acc_train_8_3, rec_test_8_3, rec_train_8_3 = modeling(\n",
    "    clf=pipe8_3,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    test_size=0.2,\n",
    "    classes={'Not Accepted':0, 'Accepted':1},\n",
    "    model_name='RF 3',\n",
    "    stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:16:33.997801Z",
     "iopub.status.busy": "2022-11-13T20:16:33.996687Z",
     "iopub.status.idle": "2022-11-13T20:16:35.57365Z",
     "shell.execute_reply": "2022-11-13T20:16:35.572524Z",
     "shell.execute_reply.started": "2022-11-13T20:16:33.997751Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print result for check overfit\n",
    "print(f\"Train Accuracy: {acc_train_8_3}\")\n",
    "print(f\"Test Accuracy: {acc_test_8_3}\")\n",
    "print(f\"Train Recall: {rec_train_8_3}\")\n",
    "print(f\"Test Recall: {rec_test_8_3}\")\n",
    "print(f\"OOB score: {rf.oob_score_}\")\n",
    "\n",
    "rf.fit(x_train,y_train.ravel())\n",
    "y_train_predicted=rf.predict(x_train)\n",
    "y_test_predicted=rf.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_test_predicted)\n",
    "plot_confusion_matrix2(cm=cm, classes={'Not Accepted':0, 'Accepted':1}, )\n",
    "# print(classification_report(y_test, y_test_predicted))\n",
    "cm = confusion_matrix(y_train, y_train_predicted)\n",
    "plot_confusion_matrix2(cm=cm, classes={'Not Accepted':0, 'Accepted':1}, )\n",
    "# print(classification_report(y_train, y_train_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:16:35.575601Z",
     "iopub.status.busy": "2022-11-13T20:16:35.575238Z",
     "iopub.status.idle": "2022-11-13T20:16:43.020243Z",
     "shell.execute_reply": "2022-11-13T20:16:43.018625Z",
     "shell.execute_reply.started": "2022-11-13T20:16:35.57557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from typing import OrderedDict\n",
    "\n",
    "ensemble_clfs = [\n",
    "    (\n",
    "        \"RandomForestClassifier, max_features='sqrt'\",\n",
    "        RandomForestClassifier(\n",
    "            warm_start=True,\n",
    "            oob_score=True,\n",
    "            criterion='entropy',\n",
    "            n_estimators=150,\n",
    "            max_samples=None,\n",
    "            max_depth=4,\n",
    "            class_weight='balanced_subsample',\n",
    "            max_features='sqrt',\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"RandomForestClassifier, max_features='log2'\",\n",
    "        RandomForestClassifier(\n",
    "            warm_start=True,\n",
    "            oob_score=True,\n",
    "            criterion='entropy',\n",
    "            n_estimators=150,\n",
    "            max_samples=None,\n",
    "            max_depth=4,\n",
    "            class_weight='balanced_subsample',\n",
    "            max_features=\"log2\",\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"RandomForestClassifier, max_features=5\",\n",
    "        RandomForestClassifier(\n",
    "            warm_start=True,\n",
    "            oob_score=True,\n",
    "            criterion='entropy',\n",
    "            n_estimators=150,\n",
    "            max_samples=None,\n",
    "            max_depth=4,\n",
    "            class_weight='balanced_subsample',\n",
    "            max_features=5,\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Map a classifier name to a list of (<n_estimators>, <error rate>) pairs.\n",
    "error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
    "\n",
    "# Range of `n_estimators` values to explore.\n",
    "min_estimators = 15\n",
    "max_estimators = 150\n",
    "\n",
    "for label, clf in ensemble_clfs:\n",
    "    for i in range(min_estimators, max_estimators + 1, 5):\n",
    "        clf.set_params(n_estimators=i)\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        # Record the OOB error for each `n_estimators=i` setting.\n",
    "        oob_error = 1 - clf.oob_score_\n",
    "        error_rate[label].append((i, oob_error))\n",
    "\n",
    "# Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n",
    "for label, clf_err in error_rate.items():\n",
    "    xs, ys = zip(*clf_err)\n",
    "    plt.plot(xs, ys, label=label)\n",
    "\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"OOB error rate\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't seem overfit, so there is no problem. Very Nice result, because only 7 of the customers who accepted the bank loan were wrongly predicted ü•≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:16:43.023124Z",
     "iopub.status.busy": "2022-11-13T20:16:43.022051Z",
     "iopub.status.idle": "2022-11-13T20:16:48.543039Z",
     "shell.execute_reply": "2022-11-13T20:16:48.541708Z",
     "shell.execute_reply.started": "2022-11-13T20:16:43.023051Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check improve model by change test_size\n",
    "change_test_size(pipe8_3, x, y, 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So best model by Decision Tree algorithm is the model by test_size = 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:16:48.544747Z",
     "iopub.status.busy": "2022-11-13T20:16:48.544407Z",
     "iopub.status.idle": "2022-11-13T20:16:48.558368Z",
     "shell.execute_reply": "2022-11-13T20:16:48.556813Z",
     "shell.execute_reply.started": "2022-11-13T20:16:48.544718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# add best model and its accuracy and recall\n",
    "best_model_test.loc[len(best_model_test.index)] = [f\"Random Forest\", '0.2', acc_test_8_3, rec_test_8_3]\n",
    "best_model_train.loc[len(best_model_train.index)] = [f\"Random Forest\", '0.2', acc_train_8_3, rec_train_8_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"compare\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:120%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">7. Comparing Models </p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after checking the performance of several different models, the following results were obtained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:16:48.560766Z",
     "iopub.status.busy": "2022-11-13T20:16:48.560178Z",
     "iopub.status.idle": "2022-11-13T20:16:48.58218Z",
     "shell.execute_reply": "2022-11-13T20:16:48.580855Z",
     "shell.execute_reply.started": "2022-11-13T20:16:48.560719Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# tabel of best models by Test_Accuracy\n",
    "best_model_test.sort_values(by=['Test_Recall'], ascending=False).reset_index(drop=True).style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"font-size:14px; font-family:verdana;\">\n",
    "    ‚úÖ We analyzed the Personal Loan campaign data using EDA and by using different models. Finally, according to the above table, the model made with Random Forest is the best model for the intended purpose (lower recall) by Test_Rcall=0.97, Test_Accuracy=0.96.ü§©\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualize\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:120%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">8. Visualization Final Model </p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:16:48.583772Z",
     "iopub.status.busy": "2022-11-13T20:16:48.58344Z",
     "iopub.status.idle": "2022-11-13T20:16:48.59535Z",
     "shell.execute_reply": "2022-11-13T20:16:48.594123Z",
     "shell.execute_reply.started": "2022-11-13T20:16:48.583743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_visual = df.drop('Personal Loan', axis=1)\n",
    "y_visual = df['Personal Loan'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:16:48.597398Z",
     "iopub.status.busy": "2022-11-13T20:16:48.597006Z",
     "iopub.status.idle": "2022-11-13T20:16:48.622949Z",
     "shell.execute_reply": "2022-11-13T20:16:48.621547Z",
     "shell.execute_reply.started": "2022-11-13T20:16:48.597353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:16:48.624935Z",
     "iopub.status.busy": "2022-11-13T20:16:48.62455Z",
     "iopub.status.idle": "2022-11-13T20:16:50.251968Z",
     "shell.execute_reply": "2022-11-13T20:16:50.250848Z",
     "shell.execute_reply.started": "2022-11-13T20:16:48.624903Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_visual, y_visual, test_size=0.2, random_state=0, stratify=y_visual)\n",
    "pipe8_3.fit(x_train, y_train.ravel())\n",
    "y_pred_test = pipe8_3.predict(x_test)\n",
    "y_pred_train = pipe8_3.predict(x_train)\n",
    "x_test.insert(11,'Personal Loan', y_test)\n",
    "x_test.insert(12, 'Pred', y_pred_test)\n",
    "x_train.insert(11,'Personal Loan', y_train)\n",
    "x_train.insert(12, 'Pred', y_pred_train)\n",
    "cols =['Age', 'Experience', 'Family', 'CCAvg', 'Education', 'Mortgage', 'Securities Account', 'CD Account', 'Online', 'CreditCard']\n",
    "\n",
    "for col in cols:\n",
    "    fig = px.scatter_3d(\n",
    "        data_frame= x_test,\n",
    "        x=x_test.Income,\n",
    "        y=x_test[col],\n",
    "        z=x_test['Personal Loan'],\n",
    "        color=y_pred_test,\n",
    "        color_discrete_map={0:'red', 1:'orange'},\n",
    "        template='ggplot2',\n",
    "        hover_name='Age',\n",
    "        # hover_data=\n",
    "        opacity=0.6,\n",
    "        # symbol='Transmission',\n",
    "        # symbol_map=\n",
    "        # log_x=True,\n",
    "        # log_z=True,\n",
    "        height=700,\n",
    "        title=f'Visualization Performance of Model in Predicting')\n",
    "\n",
    "    pio.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:16:50.253815Z",
     "iopub.status.busy": "2022-11-13T20:16:50.253365Z",
     "iopub.status.idle": "2022-11-13T20:16:50.278166Z",
     "shell.execute_reply": "2022-11-13T20:16:50.276842Z",
     "shell.execute_reply.started": "2022-11-13T20:16:50.253759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fn_rows_train = x_train[(x_train['Personal Loan'] == 1) & (x_train['Pred'] == 0)]\n",
    "fn_rows_test = x_test[(x_test['Personal Loan'] == 1) & (x_test['Pred'] == 0)]\n",
    "fn_rows = pd.concat([fn_rows_train, fn_rows_test])\n",
    "fn_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "Accoring to above plots and table:\n",
    " - Most of the data are predicted correctly and there are few errors\n",
    "\n",
    " - Our final model predicted 7 customers wrongly. On analyzing the Income , Education,Family , we can see the Income is not in range of High income group (more than $10thousand) and education is 1 (undergrad) for most of them and there CCavg is also low. These cases are some exceptions.\n",
    "\n",
    " - So for this bank we can have different profiles for customers.\n",
    " - **High Profile Clients:** Higher Income,Advanced/Graduate level Education, 3-4 Family members,high CCAvg\n",
    " - **Average Profile:** Medium Income,Graduate level Education, 3-4 Family members,medium CCAvg\n",
    " - **Low Profile:** Lower income,undergrads Education,3-4 Family members,low CCAvg\n",
    " - CCavg and Mortages can also be looked upon as based on EDA and this features also play some role in likelihood of buy loan.\n",
    " - We can 1st target high profile customers , by providing them with a personal relationship managers who can address there concerns and can pursue them to buy loan from the bank with completive interest rates.\n",
    " - Our 2nd target would be Medium profile customers.\n",
    " - The model cannot identify well if there are some exceptional cases when low profile customer is ready to buy a personal loan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"predict\"></a>\n",
    "# <p style=\"background-color:#0c4510;font-family:newtimeroman;font-size:120%;color:orange;text-align:center;border-radius:15px 50px; padding:7px\">9. Prediction Sample Data</p>\n",
    "\n",
    "[üè† Tabel of Contents](#tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:16:50.280044Z",
     "iopub.status.busy": "2022-11-13T20:16:50.279654Z",
     "iopub.status.idle": "2022-11-13T20:16:50.303059Z",
     "shell.execute_reply": "2022-11-13T20:16:50.301885Z",
     "shell.execute_reply.started": "2022-11-13T20:16:50.280011Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-13T20:51:20.109886Z",
     "iopub.status.busy": "2022-11-13T20:51:20.109458Z",
     "iopub.status.idle": "2022-11-13T20:51:21.190983Z",
     "shell.execute_reply": "2022-11-13T20:51:21.189815Z",
     "shell.execute_reply.started": "2022-11-13T20:51:20.109855Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# fit final model on all of data (train + test)\n",
    "final_model = pipe8_3\n",
    "final_model.fit(x_visual, y_visual)\n",
    "\n",
    "# define sample data\n",
    "sample = pd.DataFrame({'Age':[42], 'Experience':[16], 'Income':[30/12], 'Family':[3], 'CCAvg':[1.2], 'Education':[3], 'Mortgage':[0], 'Securities Account':[1], 'CD Account':[0], 'Online':[1], 'CreditCard':[1],})\n",
    "print(f\"Age: {sample['Age'].values[0]}\\n\"\n",
    "      f\"Experience: {sample['Experience'].values[0]}\\n\"\n",
    "      f\"Income: {sample['Income'].values[0]}\\n\"\n",
    "      f\"Family: {sample['Family'].values[0]}\\n\"\n",
    "      f\"CCAvg: {sample['CCAvg'].values[0]}\\n\"\n",
    "      f\"Education: {sample['Education'].values[0]}\\n\"\n",
    "      f\"Mortgage: {sample['Mortgage'].values[0]}\\n\"\n",
    "      f\"Securities Account: {sample['Securities Account'].values[0]}\\n\"\n",
    "      f\"CD Account: {sample['CD Account'].values[0]}\\n\"\n",
    "      f\"Online: {sample['Online'].values[0]}\\n\"\n",
    "      f\"CreditCard: {sample['CreditCard'].values[0]}\\n\")\n",
    "\n",
    "# predict sample data\n",
    "result = final_model.predict(sample)\n",
    "\n",
    "print('='*38)\n",
    "print(f\"Predict whether the customer will accept a personal loan? (0:No & 1:Yes): {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><center><img src='https://www.gifcen.com/wp-content/uploads/2021/05/the-end-gif-12.gif' height=100px width=300px></center><br>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2633609,
     "sourceId": 4505498,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
